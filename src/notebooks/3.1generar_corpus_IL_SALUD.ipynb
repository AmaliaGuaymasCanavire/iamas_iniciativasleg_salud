{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "88c0371e-cf98-4612-af96-b3fb1059c27f",
   "metadata": {},
   "source": [
    "# Generar Corpus en base a títulos de IL sobre Salud (IL)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fc60433-64ad-477d-a00b-1a4f1ba30bad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importar librerias\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "import sweetviz as sv\n",
    "\n",
    "# Visualización\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "from matplotlib.lines import Line2D\n",
    "import matplotlib.colors as mcolors\n",
    "from matplotlib import colormaps\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a19fcf6-aac3-45ea-aadc-37a6ed9e65e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configurar path\n",
    "os.chdir('C://iamas_datos2024/proyectos_parlamentarios_2025/')\n",
    "pd.set_option('display.max_colwidth', None)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efbe3034-9d75-481a-a5f3-a22b4bff9939",
   "metadata": {},
   "source": [
    "## 1 - Recolección de datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab476ef6-6b58-41e5-9ee1-a791e3616084",
   "metadata": {},
   "outputs": [],
   "source": [
    "# abrir el archivo binario proyecto filtrado\n",
    "with open('proyecto_2009_2024_df_LIMPIO2.pkl', 'rb') as file:\n",
    "    proyecto_2009_2024_df_LIMPIO = pickle.load(file)\n",
    "\n",
    "#Mostrar\n",
    "proyecto_2009_2024_df_LIMPIO.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "572b8f06-6ebc-42a2-a9bb-db8e6773398d",
   "metadata": {},
   "source": [
    "## 2 - EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e24eacd3-8d01-4899-bda5-8cd5e345030c",
   "metadata": {},
   "outputs": [],
   "source": [
    "proyecto_2009_2024_df_LIMPIO.describe(include='all').T"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a8aa012-92d0-40fd-8ed3-4944d2c69be7",
   "metadata": {},
   "source": [
    "**Tratamiento de datos faltantes**\n",
    "* Ver notebooks 2.1 y 2.2\n",
    "* Duración_dias_prep, es la diferencia entre fecha de publicación y fecha maxima de movimiento úttimo. Hay valores negativos. Se los considero valores faltantes. Todos los valores faltantes se los considero -1\n",
    "* Resultado. Para valores faltantes se agregaron dos categorias posible, 'NO TUVO TRATAMIENTO POSTERIOR NI DICTAMEN' o 'SIN INFORMACIÓN DE RESULTADO DE PROYECTO' (del cruzar fuentes de datos).\n",
    "* Periodo, tiene valores faltantes en meses del 2009 y del 2024, que no pueden ser considerados dentro posibles períodos. La recolección se hizo por años, entre 2009 a 2024.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67256c71-7cb2-44e4-972a-e1ed468e45fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Controlar nulos\n",
    "proyecto_2009_2024_df_LIMPIO.isnull().mean().sort_values(ascending=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54569554-860d-4a2f-b94e-5bb99b0d4d97",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(4, 2, figsize=(30, 15))\n",
    "sns.countplot(x='Tipo',  data=proyecto_2009_2024_df_LIMPIO, ax = axs[0][0])\n",
    "sns.countplot(x='Proyecto_girado_a_comisiones_SALUD',  data=proyecto_2009_2024_df_LIMPIO, ax = axs[0][1])\n",
    "sns.countplot(x='Proyecto_SALUD',  data=proyecto_2009_2024_df_LIMPIO, ax = axs[1][0])\n",
    "sns.boxplot(data = proyecto_2009_2024_df_LIMPIO, x = 'Max_Orden', ax = axs[1][1] ) \n",
    "sns.boxplot(data = proyecto_2009_2024_df_LIMPIO, x = 'Diferencia_ID', ax = axs[2][0] ) \n",
    "sns.boxplot(data = proyecto_2009_2024_df_LIMPIO[proyecto_2009_2024_df_LIMPIO['Duración_dias_prep']>=0], x = 'Duración_dias_prep', ax = axs[2][1] ) \n",
    "sns.countplot(x='Tiene_antecedente_por_titulo_proy',  data=proyecto_2009_2024_df_LIMPIO, ax = axs[3][0])\n",
    "\n",
    "axs[0][0].set_title('Cantidad de Iniciativas legislativas (IL) por Tipo')\n",
    "axs[0][0].set_ylabel(\"Cantidad de IL\")\n",
    "axs[0][0].set_xlabel(\"Tipo de proyectos\")\n",
    "axs[0][1].set_title('Cantidad de Iniciativas legislativas (IL) según tipo de comisión asociado a SALUD')\n",
    "axs[0][1].set_xlabel(\"COMISIONES\")\n",
    "axs[0][1].set_ylabel(\"Cantidad de IL\")\n",
    "axs[1][0].set_title('Cantidad de Iniciativas legislativas (IL) según tipo de comisión de cabecera asociado a SALUD')\n",
    "axs[1][0].set_ylabel(\"Cantidad de IL\")\n",
    "axs[1][1].set_title(' Boxplot de Máximo orden de giro a comisión')\n",
    "axs[1][1].set_xlabel(\"Máximo orden\")\n",
    "axs[1][1].set_ylabel(\"Cantidad de IL\")\n",
    "axs[2][0].set_title(' Boxplot de Diferencia_ID')\n",
    "axs[2][0].set_xlabel(\"Diferencia de ID de IL\")\n",
    "axs[2][0].set_ylabel(\"Cantidad de IL\")\n",
    "axs[2][1].set_title(' Boxplot de Duración_dias (sin valores faltantes)')\n",
    "axs[2][1].set_xlabel(\"Duración en dias\")\n",
    "axs[2][1].set_ylabel(\"Cantidad de IL\")\n",
    "axs[3][0].set_title('Cantidad de Iniciativas legislativas (IL) según si tiene antecedente por IL con igual titulo (sin procesar texto)')\n",
    "axs[3][0].set_xlabel(\"Tiene antecedente de proyecto por igual título \")\n",
    "axs[3][0].set_ylabel(\"Cantidad de IL\")\n",
    "\n",
    "fig.delaxes(axs[3][1])\n",
    "plt.tight_layout(pad=2)\n",
    "plt.subplots_adjust(bottom=0.2)\n",
    "plt.savefig(\"EDA_2009_2024.png\")\n",
    "plt.show()\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abcd11a5-206e-4b10-9e52-1be411a46673",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Resumen\n",
    "periodo_tipo_df = pd.pivot_table(proyecto_2009_2024_df_LIMPIO, values=['Proyecto.ID'], index=['Periodo','Tipo','Proyecto_girado_a_comisiones_SALUD','Proyecto_SALUD','Tiene_antecedente_por_titulo_proy','Resultado'],\n",
    "                       aggfunc={'Proyecto.ID': \"count\"                               \n",
    "                               }).reset_index()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9550cfa8-2579-4c83-a696-2f4f52141238",
   "metadata": {},
   "outputs": [],
   "source": [
    "f, axs = plt.subplots(4, 2, figsize=(40, 20), sharey = True)\n",
    "sns.lineplot(x=periodo_tipo_df['Periodo'], y=periodo_tipo_df['Proyecto.ID'], estimator='sum', errorbar= None , linestyle='-', ax = axs[0][0], marker=\"o\")\n",
    "sns.lineplot(x=periodo_tipo_df['Periodo'], y=periodo_tipo_df['Proyecto.ID'], estimator='sum',  hue = 'Proyecto_girado_a_comisiones_SALUD', marker=\"o\" ,data =periodo_tipo_df,  errorbar= None , linestyle='-',ax = axs[0][1])\n",
    "sns.lineplot(x=periodo_tipo_df['Periodo'], y=periodo_tipo_df['Proyecto.ID'], estimator='sum',  hue = 'Tipo', data =periodo_tipo_df,  marker=\"o\", errorbar= None , linestyle='-',ax = axs[1][0])\n",
    "sns.lineplot(x=periodo_tipo_df['Periodo'], y=periodo_tipo_df['Proyecto.ID'], estimator='sum',  hue = 'Tipo', \n",
    "style=\"Proyecto_girado_a_comisiones_SALUD\", data =periodo_tipo_df,  errorbar= None , linestyle='-',ax = axs[1][1], marker=\"o\")\n",
    "sns.lineplot(x=periodo_tipo_df['Periodo'], y=periodo_tipo_df['Proyecto.ID'], estimator='sum',  hue = 'Proyecto_SALUD', marker=\"o\" ,data =periodo_tipo_df,  errorbar= None , linestyle='-',ax = axs[2][0])\n",
    "sns.lineplot(x=periodo_tipo_df['Periodo'], y=periodo_tipo_df['Proyecto.ID'], estimator='sum',  hue = 'Tipo', \n",
    "style=\"Proyecto_SALUD\", data =periodo_tipo_df,  errorbar= None , linestyle='-',ax = axs[2][1], marker=\"o\")\n",
    "sns.lineplot(x=periodo_tipo_df['Periodo'], y=periodo_tipo_df['Proyecto.ID'], estimator='sum',  hue = 'Tiene_antecedente_por_titulo_proy', marker=\"o\" ,data =periodo_tipo_df,  errorbar= None , linestyle='-',ax = axs[3][0])\n",
    "sns.lineplot(x=periodo_tipo_df['Periodo'], y=periodo_tipo_df['Proyecto.ID'], estimator='sum',  hue = 'Tiene_antecedente_por_titulo_proy', \n",
    "style=\"Proyecto_SALUD\", data =periodo_tipo_df,  errorbar= None , linestyle='-',ax = axs[3][1], marker=\"o\")\n",
    "\n",
    "axs[0][0].axhline(y=periodo_tipo_df.groupby('Periodo')['Proyecto.ID'].sum().mean(), color='r', linestyle='--')\n",
    "axs[0][0].set_title('Cantidad de Iniciativas legislativas (IL) por Periodo')\n",
    "axs[0][0].set_xlabel(\"Periodo (publicación)\")\n",
    "axs[0][0].set_ylabel(\"Cantidad de IL\")\n",
    "axs[0][1].set_title('Cantidad de Iniciativas legislativas (IL) por Periodo y Comisión SALUD U OTRAS')\n",
    "axs[0][1].set_xlabel(\"Periodo (publicación)\")\n",
    "axs[1][0].set_title('Cantidad de Iniciativas legislativas (IL) por Periodo y Tipo')\n",
    "axs[1][0].set_xlabel(\"Periodo (publicación)\")\n",
    "axs[1][1].set_title('Cantidad de Iniciativas legislativas (IL) por Periodo, Tipo y Comisión SALUD U OTRAS')\n",
    "axs[1][1].set_xlabel(\"Periodo (publicación)\")\n",
    "axs[2][0].set_title('Cantidad de Iniciativas legislativas (IL) por Periodo y SALUD')\n",
    "axs[2][0].set_xlabel(\"Periodo (publicación)\")\n",
    "axs[2][1].set_title('Cantidad de Iniciativas legislativas (IL) por Periodo, Tipo  y SALUD')\n",
    "axs[2][1].set_xlabel(\"Periodo (publicación)\")\n",
    "axs[3][0].set_title('Cantidad de Iniciativas legislativas (IL) por Periodo y tiene antecedente por titulo proy')\n",
    "axs[3][0].set_xlabel(\"Periodo (publicación)\")\n",
    "axs[3][1].set_title('Cantidad de Iniciativas legislativas (IL) por Periodo, tiene antecedente por titulo proy y SALUD')\n",
    "axs[3][1].set_xlabel(\"Periodo (publicación)\")\n",
    "\n",
    "plt.tight_layout(pad=2)\n",
    "plt.subplots_adjust(bottom=0.2)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e115e162-f001-429c-9e25-d2193e40dad2",
   "metadata": {},
   "source": [
    "## 3 -Limpieza y preparación de los datos "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97ddf9e3-3bf9-449c-a5a4-06e1377cfae7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Librerias para texto\n",
    "#import gensim\n",
    "import re\n",
    "#from gensim.corpora import Dictionary\n",
    "import nltk\n",
    "import spacy\n",
    "\n",
    "# https://pypi.org/project/textacy/\n",
    "import textacy\n",
    "import textacy.preprocessing as tprep\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d167541-d9c2-4c7b-8247-8f5ed75ae2e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Seleccionamos texto\n",
    "texto_df = proyecto_2009_2024_df_LIMPIO[['Proyecto.ID','Título']]\n",
    "texto_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b30772a-36f5-41b1-bccc-dc44c19f4c68",
   "metadata": {},
   "source": [
    "Los títulos de los IL presentan entre 0 y 600 caracteres."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99f6c4ea-fef0-458f-8938-f04c113b6f56",
   "metadata": {},
   "outputs": [],
   "source": [
    "texto_df['Título'].str.len().hist(bins='auto')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6caf20cb-2ed8-44b2-8382-4666cde12445",
   "metadata": {},
   "outputs": [],
   "source": [
    "texto_df['Título'].str.len().describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54a506bc-f3a4-476c-96ae-54fb19bc884b",
   "metadata": {},
   "source": [
    "Los títulos de los IL presenta en promedio 27 palabras, min 2 palabras max 217 palabras."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fcf31c8-859f-4e5e-8878-00ef88a39cee",
   "metadata": {},
   "outputs": [],
   "source": [
    "texto_df['Título'].str.split().map(lambda x: len(x)).describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a4b378d-9cbe-4fba-9cf4-04f74791dfdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "texto_df['Título'].str.split().map(lambda x: len(x)).hist(bins='auto')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "451893da-0dd3-4761-a570-f7a66777c72e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cantidad de palabras # tokens\n",
    "proyecto_2009_2024_df_LIMPIO['Cant_palabras_aprox'] = proyecto_2009_2024_df_LIMPIO['Título'].str.split().map(lambda x: len(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fffebb98-4d67-4015-9a71-964435ade914",
   "metadata": {},
   "source": [
    "#### Relación con variables númericas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8e7bc2d-4467-42a3-a8f2-953682ed9745",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Seleccionar solo las columnas númericas\n",
    "columnas_numericas = proyecto_2009_2024_df_LIMPIO.select_dtypes(include=[np.number]).columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8625c876-f5e7-45c4-a5f0-c49349a1f5d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "columnas_numericas = ['Max_Orden', 'Duración_dias_prep', 'Diferencia_ID', 'Periodo', 'Año','Cant_palabras_aprox']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68bfb507-ce2d-4eea-9add-5d4e631a6252",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.pairplot(proyecto_2009_2024_df_LIMPIO[columnas_numericas], diag_kind=\"kde\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f96180f8-5445-4689-973a-7eca2b774b8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Correlación\n",
    "correlaccion = proyecto_2009_2024_df_LIMPIO[columnas_numericas].corr(method='pearson')\n",
    "sns.heatmap(correlaccion,xticklabels=correlaccion.columns,\n",
    "yticklabels=correlaccion.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b24dd79a-cda0-40ca-99df-1d840b1f0d96",
   "metadata": {},
   "source": [
    "#### Relación con variables categóricas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74b90c4a-dadc-464a-b073-6af8c8044950",
   "metadata": {},
   "outputs": [],
   "source": [
    "proyecto_2009_2024_df_LIMPIO.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea050b76-7ba2-41e3-935a-a40829986e5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "columnas_categ = ['Proyecto_SALUD','Tipo', 'Año','Periodo','Tiene_antecedente_por_titulo_proy']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e750410-abb1-4f9a-a9a1-821fbe06267a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calcular el número de filas y columnas para el subplot\n",
    "n = len(columnas_categ)\n",
    "nrows = 4\n",
    "ncols = min(n, 2)\n",
    "\n",
    "# Crear la figura y los subplots\n",
    "fig, axes = plt.subplots(nrows=nrows, ncols=ncols, figsize=(15, 5*nrows))\n",
    "fig.suptitle('Distribución de Variables Categóricas', fontsize=16)\n",
    "\n",
    "\n",
    "# Aplanar el array de ejes en caso de que sea 2D\n",
    "axes = axes.flatten() if n > 3 else [axes]\n",
    "\n",
    "# Crear histogramas para cada variable numérica\n",
    "for i, col in enumerate(columnas_categ):\n",
    "    ax = axes[i]\n",
    "    sns.violinplot(data=proyecto_2009_2024_df_LIMPIO, x=col, y=\"Cant_palabras_aprox\", ax = ax )\n",
    "    ax.set_title(f'Distribución de {col}')\n",
    "    ax.set_xlabel('')\n",
    "    ax.set_ylabel('Cant_palabras_aprox')\n",
    "    ax.tick_params(\"x\", rotation=45)\n",
    "\n",
    "# Ocultar subplots vacíos si los hay\n",
    "for j in range(i+1, len(axes)):\n",
    "    fig.delaxes(axes[j])\n",
    "\n",
    "\n",
    "plt.tight_layout(pad=2)\n",
    "plt.subplots_adjust(bottom=0.2)\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b80f7fb-86d3-4bee-b431-d71aee9ab916",
   "metadata": {},
   "source": [
    "#### Correlación"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e8ac492-9316-45a1-b96e-06b710363ccf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.stats as stats\n",
    "\n",
    "# Prueba ANOVA y Kruskal-Wallis para comparar medias de variables numéricas según categorías#https://docs.scipy.org/doc/scipy/reference/generated/scipy.stats.f_oneway.html\n",
    "anova_results = {}\n",
    "kruskal_results = {}\n",
    "num_var = 'Cant_palabras_aprox'\n",
    "for cat_var in columnas_categ:\n",
    "    groups = [group[num_var].dropna() for name, group in proyecto_2009_2024_df_LIMPIO.groupby(cat_var)]\n",
    "    if len(groups) > 1:\n",
    "        stat, p_value_anova = stats.f_oneway(*groups)\n",
    "        stat_kruskal, p_value_kruskal = stats.kruskal(*groups)\n",
    "        anova_results[f'{num_var} ~ {cat_var}'] = p_value_anova\n",
    "        kruskal_results[f'{num_var} ~ {cat_var}'] = p_value_kruskal\n",
    "\n",
    "print(\"Resultados de la prueba ANOVA:\")\n",
    "for key, value in anova_results.items():\n",
    "    print(f'{key}: p-value = {value}')\n",
    "\n",
    "print(\"\\nResultados de la prueba Kruskal-Wallis:\")\n",
    "for key, value in kruskal_results.items():\n",
    "    print(f'{key}: p-value = {value}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92efae23-7d5e-4bc7-b86e-9ad6c8e9fd22",
   "metadata": {},
   "source": [
    "Viendo como se distribuyen los titulos por Tipo de proyecto (IL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "540e16ad-742e-4d0b-a3c3-9be5c5341a3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Explorando por Tipo de proyecto\n",
    "\n",
    "pd.pivot_table(proyecto_2009_2024_df_LIMPIO, values=['Cant_palabras_aprox'], index=['Tipo'],\n",
    "                       aggfunc={'Cant_palabras_aprox': ('mean',\"min\",\"max\")}).reset_index()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54071b43-560b-461e-9305-6308672a063c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Draw a nested violinplot and split the violins for easier comparison\n",
    "fig, ax = plt.subplots(1,1, figsize=(15, 5))\n",
    "sns.violinplot(data=proyecto_2009_2024_df_LIMPIO, x=\"Tipo\", y=\"Cant_palabras_aprox\", hue=\"Proyecto_SALUD\", ax=ax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ddd751d-ad6c-483c-bb23-122895f8d888",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Proyectos con titulos con dos palabras\n",
    "proyecto_2009_2024_df_LIMPIO.loc[proyecto_2009_2024_df_LIMPIO['Cant_palabras_aprox'] == 2, ['Proyecto.ID','Título','Tiene_antecedente_por_titulo_proy','Tipo','Max_Orden','Periodo','Publicación.Fecha']].sort_values('Publicación.Fecha')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa52a042-226e-4448-91a4-4858edd5372e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analizando por cantidad promedio de palabras por, Periodo, Tipo y girado a comisiones de salud\n",
    "periodo_tipo_df = pd.pivot_table(proyecto_2009_2024_df_LIMPIO, values=['Cant_palabras_aprox'], index=['Periodo','Tipo','Proyecto_SALUD'],\n",
    "                       aggfunc={'Cant_palabras_aprox': \"mean\"}).reset_index()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e47a08be-7661-42ab-a436-46f96a9ac5ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "periodo_tipo_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f02d0d12-5bce-4119-abe6-0221d89dbb67",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15, 5))\n",
    "g = sns.relplot(\n",
    "    data=periodo_tipo_df, x=\"Periodo\", y=\"Cant_palabras_aprox\", col=\"Proyecto_SALUD\",\n",
    "    hue=\"Tipo\",  kind=\"line\", estimator = 'sum', errorbar= None, marker='o',\n",
    ")\n",
    "\n",
    "(g.set_axis_labels(\"Periodo\", \"Cantidad de palabras (media)\")\n",
    "  .tight_layout(w_pad=0))\n",
    "\n",
    "plt.savefig(\"output.png\", dpi=100, bbox_inches=\"tight\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24ef539b-863a-40bd-85c4-c52b79fa2b11",
   "metadata": {},
   "source": [
    "Nos centraremos en IL por ley y exploraremos que pasa en salud. \n",
    " * Los IL por tipo LEY presenta en promedio 21 palabras."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67c50555-6081-4580-af04-243acaecaaaa",
   "metadata": {},
   "source": [
    "## NLP para IL - proyectos de ley \n",
    "#### Preprocesamiento de textos\n",
    "\n",
    "La normalización es una tarea que tiene como objetivo poner todo el texto en igualdad de condiciones:\n",
    "\n",
    "* ✅ Eliminar  carácteres como puntos, comas, comillas, espacios, brackets, etc.\n",
    "* ✅ Convertir los números a su equivalente a palabras\n",
    "* ✅ Convertir a minúsculas\n",
    "* ✅ Lematizar\n",
    "* ✅ Tokenizar\n",
    "* ✅ Remover stopwords (opcional)\n",
    "* ✅ Identificar palabras asociadas a dominio de las leyess\n",
    "* ✅ Filtrar palabras asociadas a dominio\n",
    "\n",
    "    * Tokenization: Tarea de dividir grandes cadenas de texto solo y exclusivamente en palabras.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92b33927-58e3-4896-a5be-88bc64f5b871",
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://github.com/RicardoMoya/NLP_with_Python/blob/master/04_Preprocesamiento_de_textos_Normalizacion.ipynb\n",
    "\n",
    "####GENERALES####\n",
    "from spacy.lang.es.stop_words import STOP_WORDS\n",
    "import spacy\n",
    "from collections import Counter\n",
    "from itertools import islice\n",
    "\n",
    "####DOMINIO####\n",
    "#stopwords_dominio = ['numero','articulo','ley','expediente','codigo','ano','modificación','bis']  \n",
    "#for word in stopwords_dominio:\n",
    "#    STOP_WORDS.add(word)\n",
    "\n",
    "# Para limpiar simbolos\n",
    "\n",
    "import pandas as pd\n",
    "import spacy\n",
    "\n",
    "# Cargar modelo de spaCy para español\n",
    "nlp = spacy.load(\"es_core_news_md\") #  # es_core_news_md\n",
    "\n",
    "\n",
    "def limpieza_basica_texto(text):\n",
    "    try: \n",
    "      \n",
    "       # Normaliza los caracteres Unicode del texto en formas canónicas. \n",
    "       text = tprep.normalize.unicode(text) \n",
    "       # Elimina los acentos de cualquier carácter Unicode acentuado en el texto, ya sea reemplazándolos con equivalentes ASCII o eliminándolos por completo. \n",
    "       text = tprep.remove.accents(text)\n",
    "       # Por tema de leyes y números \n",
    "       text = text.replace('.','') \n",
    "       # Elimine la puntuación del texto reemplazando todas las instancias de puntuación (o un subconjunto de la misma especificada por solamente) con espacios en blanco. \n",
    "       text = tprep.remove.punctuation(text) # ojo que lo reemplaza por espacio, por eso mejor normalize.whitespace al final\n",
    "       ## Elimina los espacios\n",
    "       #text = text.strip() \n",
    "       # Reemplza comillas simples y dobles a solo los equivalentes básicos de ASCII. \n",
    "       text = tprep.normalize.quotation_marks(text)\n",
    "       # Reemplaza espacios respetando la división entre palabras \n",
    "       text = tprep.normalize.whitespace(text) \n",
    "       # Reemplaza  {}, square [], and/or round ()\n",
    "       text = tprep.remove.brackets(text)\n",
    "       # Reemplaza los números por la palabra 'numero'     \n",
    "       text = tprep.replace.numbers(text,\"numero\")\n",
    "       # Pasa a minúscula\n",
    "       text = text.lower()\n",
    "    \n",
    "    \n",
    "    except:\n",
    "        print(\"Hubo un error\")\n",
    "    \n",
    "    return text\n",
    "\n",
    "def get_tokens(text):\n",
    "    \"\"\"\n",
    "    Función que dado un texto devuelve una lista con las palabras del texto no vacias\n",
    "    \"\"\"\n",
    "    doc = nlp(text)\n",
    "    return [word for word in doc if len(word.text.strip())> 0]\n",
    "\n",
    "def remove_punctuation(words):\n",
    "    \"\"\"\n",
    "    Función que dada una lista de palabras, elimina los signos de puntuación\n",
    "    \"\"\"\n",
    "    doc = spacy.tokens.doc.Doc(nlp.vocab, words=words)\n",
    "    return [word.text for word in doc if not word.is_punct]\n",
    "\n",
    "def remove_short_words(words, num_chars):\n",
    "    \"\"\"\n",
    "    Función que dada una lista de tokens y un número mínimo de caracteres que tienen que tener\n",
    "    las palabras, elimina todas las palabras que tengan menos caracteres que los indicados\n",
    "    \"\"\"\n",
    "    return \" \".join([word.text for word in words if len(word.text) > num_chars])\n",
    "\n",
    "def remove_stop_words(words):\n",
    "    \"\"\"\n",
    "    Función que dada una lista de tokens, elimina las Stop Words\n",
    "    \"\"\"\n",
    "    return [word for word in words if not word.is_stop]\n",
    "\n",
    "def to_lowercase(words):\n",
    "    \"\"\"\n",
    "    Función que dada una lista de palabras, las transforma a minúsculas\n",
    "    \"\"\"\n",
    "    return [word.lower() for word in words]\n",
    "\n",
    "def lemmatizer(words,  allowed_postags=['NOUN', 'ADJ', 'VERB', 'ADV']):\n",
    "    \"\"\"\n",
    "    Función que dada un texto, devuelve esa un texto con el lema de cada una de esas palabras\n",
    "    \"\"\"\n",
    "    doc = nlp(words)\n",
    "    lemma = \" \".join([word.lemma_ if word.lemma_ not in ['-PRON-'] else '' for word in doc if word.pos_ in allowed_postags])\n",
    "    #     \" \".join([word.lemma_ if  word.lemma_ not in ['-PRON-'] else '' for word in doc])\n",
    "    return lemma\n",
    "    \n",
    "\n",
    "\n",
    "def normalizar(text):\n",
    "    \"\"\"\n",
    "    Dado un texto, devuelve el texto tokenizado y normalizado\n",
    "    \"\"\"\n",
    "    # Lematizar\n",
    "    words = lemmatizer(text)\n",
    "    # Pasar a tokens\n",
    "    words = get_tokens(text=text)\n",
    "    # Eliminar stop words\n",
    "    words = remove_stop_words(words)\n",
    "    # Eliminar letras que pueden aparecer\n",
    "    words = remove_short_words(words=words, num_chars=1)\n",
    "    return words\n",
    "\n",
    "# https://www.datacamp.com/es/tutorial/stemming-lemmatization-python\n",
    "# Función para obtener n-gramas\n",
    "def get_ngrams(text, n):\n",
    "    doc = nlp(text)  # Procesar texto\n",
    "    tokens = [token.text for token in doc if token.is_alpha and not token.is_stop]  # Filtrar palabras\n",
    "    return list(zip(*[tokens[i:] for i in range(n)]))  # Generar n-gramas\n",
    "\n",
    "# Función para eliminar los n-gramas más frecuentes\n",
    "def remove_frequent_ngrams(text, ngrams_to_remove):\n",
    "    doc = nlp(text)\n",
    "    text_clean = text\n",
    "    for ngram in ngrams_to_remove:\n",
    "        text_clean = text_clean.replace(ngram, \"\")  # Reemplazar el n-grama con vacío\n",
    "    return \" \".join(text_clean.split())  # Limpiar espacios extras\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72b804d1-b5a9-437a-80d9-bdfb415b6fe1",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_text = 'EMERGENCIA LABORAL PARA EL PERSONAL DE LA ADMINISTRACIÓN PUBLICA NACIONAL 1.343 (VER), ARTÍCULOS'\n",
    "text = limpieza_basica_texto(base_text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1189fc51-98ca-42c2-840c-7ff2c0776f1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Probando función\n",
    "print('Texto original:',base_text)\n",
    "print('Limpieza primera:',text)\n",
    "print(\"Normalizado:\",normalizar(text))\n",
    "print(\"############################# Controlando errores de normalización\")\n",
    "doc = nlp(text)\n",
    "print('NLP spacy:',doc)\n",
    "print(\"Token sin stop word\",[word.text for word in doc if not word.is_stop])\n",
    "print('-----------------')\n",
    "print(doc)\n",
    "print(\"\\n ** Controlando lematizador:\",[(word.lemma_ , word.pos_) for word in doc] )\n",
    "allowed_postags=['NOUN', 'ADJ', 'VERB', 'ADV']\n",
    "doc2 = nlp(\" \".join([word.text for word in doc if not word.is_stop]))\n",
    "for word in doc2:\n",
    "    print(word.lemma_)\n",
    "print(\"\\n ** Controlando lematizador doc2:\",[(word.lemma_ , word.pos_) for word in doc2] )\n",
    "print(\"\\n ** Controlando lematizador con postag:\",\" \".join([word.lemma_ if word.lemma_ not in ['-PRON-'] else '' for word in doc if word.pos_ in allowed_postags]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1790cb01-93a7-4887-a1a4-0b7a9af01fa8",
   "metadata": {},
   "outputs": [],
   "source": [
    "get_ngrams(normalizar(text), 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd274913-3581-47cd-a57b-94debc0517e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Seleccionanos los textos - titulos IL de ley para 2009 a 2023 -- 33052 \n",
    "texto_df = proyecto_2009_2024_df_LIMPIO.loc[proyecto_2009_2024_df_LIMPIO['Tipo'] == 'LEY' , ['Proyecto.ID','Título']]#sample(frac=0.001, replace=True, random_state=1)\n",
    "texto_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bc860a3-8513-4d05-a24f-2d33635f60f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "texto_df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59c2e58d-b753-44b4-a74e-083b01135534",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalización\n",
    "texto_df['Título normalizado'] = texto_df['Título'].copy()\n",
    "texto_df['Título normalizado'] = texto_df['Título normalizado'].apply(limpieza_basica_texto) # caracteres especiales\n",
    "texto_df['Título normalizado'] = texto_df['Título normalizado'].apply(normalizar)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22ce9851-fc6a-4551-b6d7-b245881e4288",
   "metadata": {},
   "outputs": [],
   "source": [
    "texto_df[texto_df['Título normalizado'].isna()]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb0bb199-f8cb-4c94-b97d-eb2206202ffe",
   "metadata": {},
   "source": [
    "#### Reducción de ruido en términos genéricos\n",
    "\n",
    "Si ciertos n-gramas son muy frecuentes en todos los textos y no aportan información (ej. \"en el año\"), eliminarlos ayuda a que los embeddings reflejen conceptos más específicos del dominio."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7580909c-0030-4667-947c-745218947142",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aplicar la limpieza al DataFrame\n",
    "# Extraer n-gramas de todos los títulos\n",
    "\n",
    "ngrams2 = []\n",
    "ngrams3 = []\n",
    "for titulo in texto_df[\"Título normalizado\"]:\n",
    "    ngrams2.extend(get_ngrams(titulo, 2))\n",
    "    ngrams3.extend(get_ngrams(titulo, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "407abaa7-a5bd-4aa6-a32e-1bdec25cef8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Contar los n-gramas más comunes\n",
    "top_k = 50 # Número de n-gramas a eliminar\n",
    "ngrams_freq2 = Counter(ngrams2).most_common(top_k)\n",
    "ngrams_freq2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cca4bef-a460-4c2d-830f-394921154d12",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame.from_dict(Counter(ngrams2), orient='index', columns = ['Frecuencia']).sort_values(by = 'Frecuencia', ascending=True)\n",
    "print(df.shape)\n",
    "display(df.describe())\n",
    "df.plot.box()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e84d4384-1e91-496e-96a3-15dad18870bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Los n-gramas son secuencias de palabras, símbolos, números o puntuación que aparecen de forma consecutiva en un texto.\n",
    "fig, ax = plt.subplots(figsize=(5, 10))\n",
    "df.tail(50).plot(kind='barh', ax=ax)\n",
    "ax.set_title('Top 50 - 23-gramas más frecuentes')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0aa1f6a5-545c-4a70-9b80-9a0fb77a9e08",
   "metadata": {},
   "outputs": [],
   "source": [
    "Q1 = df['Frecuencia'].quantile(0.25)\n",
    "Q3 = df['Frecuencia'].quantile(0.75)\n",
    "IQR = Q3 - Q1\n",
    "\n",
    "# Definir los límites\n",
    "limite_inferior = Q1 - 1.5 * IQR\n",
    "limite_superior = Q3 + 1.5 * IQR\n",
    "print(limite_inferior,limite_superior)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8f1649c-01f8-4ff6-b2f5-b412fef84502",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Contar los n-gramas más comunes\n",
    "top_k = 50 # Número de n-gramas a eliminar\n",
    "ngrams_freq = Counter(ngrams3).most_common(top_k)\n",
    "ngrams_freq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0f9d1a0-f97c-4384-858e-5a881aef2673",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame.from_dict(Counter(ngrams3), orient='index', columns = ['Frecuencia']).sort_values(by = 'Frecuencia', ascending=True)\n",
    "print(df.shape)\n",
    "display(df.describe())\n",
    "df.plot.box()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d35be8b-2fdf-419b-a1be-485fb2399a10",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Los n-gramas son secuencias de palabras, símbolos, números o puntuación que aparecen de forma consecutiva en un texto.\n",
    "fig, ax = plt.subplots(figsize=(5, 10))\n",
    "df.tail(50).plot(kind='barh', ax=ax)\n",
    "ax.set_title('Top 50 - 23-gramas más frecuentes')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d22f9d06-61d1-4d2f-a9ab-a468fcd8432f",
   "metadata": {},
   "outputs": [],
   "source": [
    "Q1 = df['Frecuencia'].quantile(0.23)\n",
    "Q3 = df['Frecuencia'].quantile(0.75)\n",
    "IQR = Q3 - Q1\n",
    "\n",
    "# Definir los límites\n",
    "limite_inferior = Q1 - 1.5 * IQR\n",
    "limite_superior = Q3 + 1.5 * IQR\n",
    "print(limite_inferior,limite_superior)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8521dc88-75b0-4690-b4cd-7acddf1fdceb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def eliminar_outliers_iqr(df, columna):\n",
    "    \"\"\"\n",
    "    Separa los outliers y devuelve dos DataFrames:\n",
    "    - df_limpio: sin outliers\n",
    "    - df_outliers: con los valores atípicos detectados\n",
    "\n",
    "    Parámetros:\n",
    "    df (pd.DataFrame): DataFrame de pandas\n",
    "    columna (str): Nombre de la columna a analizar\n",
    "\n",
    "    Retorna:\n",
    "    df_limpio (pd.DataFrame): DataFrame sin outliers\n",
    "    df_outliers (pd.DataFrame): DataFrame solo con outliers\n",
    "    \"\"\"\n",
    "    Q1 = df[columna].quantile(0.25)\n",
    "    Q3 = df[columna].quantile(0.75)\n",
    "    IQR = Q3 - Q1\n",
    "   \n",
    "    # Definir los límites\n",
    "    limite_inferior = Q1 - 1.5 * IQR\n",
    "    limite_superior = Q3 + 1.5 * IQR\n",
    "    print('Método IQR')\n",
    "    print('limite_inferior',limite_inferior )\n",
    "    print('limite_superior',limite_superior )\n",
    "    # Filtrar datos\n",
    "    df_limpio = df[(df[columna] >= limite_inferior) & (df[columna] <= limite_superior)]\n",
    "    df_outliers = df[(df[columna] < limite_inferior) | (df[columna] > limite_superior)]\n",
    "\n",
    "    return df_limpio, df_outliers    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44032ede-97a6-4dbc-afd5-09efcb698940",
   "metadata": {},
   "outputs": [],
   "source": [
    "#freqs_limpio_df , outliers_df = eliminar_outliers_iqr(df, 'Frecuencia')\n",
    "#display(\"Outliers detectados:\\n\", outliers_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d191217-1950-4ad0-9f48-200a0447dc9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "ngrams_freq2[:7]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f5e147d-307f-4f96-a451-a6d5c581c0b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "ngrams_to_remove = {\" \".join(ngram) for ngram, _ in ngrams_freq2[:7]}  # Convertir a conjunto\n",
    "ngrams_to_remove"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89fbd1fa-8289-496b-bd19-af8204625b1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "texto_df['Título normalizado'] = texto_df['Título normalizado'].apply(lambda x: remove_frequent_ngrams(x, ngrams_to_remove))\n",
    "texto_df['Título normalizado'] = texto_df['Título normalizado'].str.replace('numero',\"\")\n",
    "texto_df[texto_df['Título normalizado'].isna()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be331fcc-07c6-4b2b-ad9a-831c3d38dd68",
   "metadata": {},
   "outputs": [],
   "source": [
    "texto_df['Cant_token'] = texto_df['Título'].str.split().map(lambda x: len(x))\n",
    "texto_df['Cant_token_normalizado'] = texto_df['Título normalizado'].str.split().map(lambda x: len(x))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e965e15-19a0-49e2-b553-8e23ef2deb6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Distribución\n",
    "display(texto_df[['Cant_token','Cant_token_normalizado']].describe().T)\n",
    "sns.boxplot(data=texto_df[['Cant_token','Cant_token_normalizado']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1b51fa8-ddb7-47af-8015-b4a5ef994981",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Error\n",
    "Error_texto = texto_df[texto_df['Cant_token_normalizado']<1].copy()\n",
    "#Error_texto['Título normalizado'] = Error_texto['Título'].apply(limpieza_basica_texto) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "771bae63-46fc-400c-87bf-cc6daba08142",
   "metadata": {},
   "outputs": [],
   "source": [
    "Error_texto.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa320036-0809-412b-b99a-a7d1729a0f48",
   "metadata": {},
   "source": [
    "Exploramos por período\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "165cb862-fd2d-444f-95b1-2456f35ab121",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_texto_df = pd.merge(texto_df,proyecto_2009_2024_df_LIMPIO[['Proyecto.ID','Proyecto_SALUD','Resultado','Periodo']], how = 'inner',left_on = 'Proyecto.ID', right_on='Proyecto.ID' )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f36f6348-8eca-4f97-9be6-b9b17de3da15",
   "metadata": {},
   "outputs": [],
   "source": [
    "Temp = pd.pivot_table(base_texto_df, values=['Cant_token','Cant_token_normalizado'], index=['Periodo'],\n",
    "                       aggfunc={'Cant_token': 'median','Cant_token_normalizado': 'median'}).reset_index()\n",
    "Temp = pd.melt(Temp, id_vars=['Periodo'], value_vars=['Cant_token_normalizado', 'Cant_token'])\n",
    "Temp.columns = ['Periodo','Texto','Cantidad media de palabras en título de IL']\n",
    "Temp[\"Texto\"] = Temp[\"Texto\"].map({'Cant_token': 'Sin procesamiento', 'Cant_token_normalizado': 'Con procesamiento'})\n",
    "\n",
    "f, ax = plt.subplots(1, 1, figsize=(15, 5), sharey = True)\n",
    "sns.lineplot(x='Periodo', y='Cantidad media de palabras en título de IL', hue='Texto', data = Temp, estimator='sum', errorbar= None , linestyle='-', ax = ax, marker=\"o\")\n",
    "legend_handles, _= ax.get_legend_handles_labels()\n",
    "ax.set_title('Cantidad media de palabras en título de IL por Periodo')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4754876a-a824-4d57-9cdd-70715cf4ede5",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.relplot(\n",
    "    data=base_texto_df, x=\"Periodo\", y=\"Cant_token_normalizado\", col=\"Proyecto_SALUD\",\n",
    "    kind=\"line\", estimator = 'median', errorbar= None, marker='o',\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a93419d-d7db-4ea3-b1ea-2b2ccc67e151",
   "metadata": {},
   "source": [
    "Exploramos por Tipo de proyecto ley, y Resultado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8037d0e6-6bb5-4065-b7fe-0f8f47a0dec4",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.pivot_table(pd.merge(texto_df,proyecto_2009_2024_df_LIMPIO[['Proyecto.ID','Proyecto_SALUD','Resultado','Periodo']], how = 'inner',left_on = 'Proyecto.ID', right_on='Proyecto.ID' ), values=['Cant_token','Cant_token_normalizado'], index=['Resultado'],\n",
    "                       aggfunc={'Cant_token': ('mean','median',\"min\",\"max\"),'Cant_token_normalizado': ('mean','median',\"min\",\"max\")}).reset_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62c30996-06fc-4c32-9918-d46790f825b7",
   "metadata": {},
   "source": [
    "#### Creacción del diccionario y la bolsa de palabras (BoW)\n",
    "En este punto tenemos que crear:\n",
    "* Corpus tokenizado: \"documents_tok\"\n",
    "* Diccionario: \"dictionary\"\n",
    "* Corpus: \"corpus' que es la bolsa de palabras de gensim\n",
    "* Detectar palabras asociado al dominio (leyes) para eliminar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "800d9ebc-7dee-4861-8963-81df96c2284a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://github.com/RicardoMoya/NLP_with_Python/blob/master/21_Topic_Modeling_noticias.ipynb\n",
    "# https://github.com/RicardoMoya/NLP_with_Python/blob/master/05_Bag_of_Words_BoW.ipynb\n",
    "\n",
    "#import gensim\n",
    "#import gensim.corpora as corpora\n",
    "from pprint import pprint\n",
    "#from gensim import corpora\n",
    "from collections import defaultdict\n",
    "from collections import Counter\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9c1100d-4fcd-423c-8d6a-261a7c654ab4",
   "metadata": {},
   "outputs": [],
   "source": [
    "##################################PASOS DICCIONARIO########################\n",
    "corpus_norm = list(texto_df['Título normalizado'])\n",
    "# Tokenizamos\n",
    "documents_tok = [word.split() for word in corpus_norm]\n",
    "\n",
    "# Creamos el diccionario (vocabulario)\n",
    "frequency = defaultdict(int)\n",
    "for doc in documents_tok:\n",
    "    for token in doc:\n",
    "        frequency[token] += 1\n",
    "\n",
    "# Exploramos todas las palabras para limpiar mejor\n",
    "#counter = Counter(frequency)\n",
    "frecuencia_df = pd.DataFrame.from_records(list(frequency.items()), columns = ['token','frecuencia'])\n",
    "display(frecuencia_df.describe())\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(5, 10))\n",
    "frecuencia_df.sort_values('frecuencia', ascending=False).head(50).plot(kind='barh', x = 'token', ax=ax)\n",
    "ax.set_title('Top 50 palabras más frecuentes')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f88555cb-0685-4a34-92a4-f70250a097c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "frecuencia_df['frecuencia'].plot(kind='box')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12148362-2e26-46d8-a68d-ea6d9420c68c",
   "metadata": {},
   "outputs": [],
   "source": [
    "####GENERALES####\n",
    "#from spacy.lang.es.stop_words import STOP_WORDS\n",
    "\n",
    "####DOMINIO####\n",
    "#stopwords_dominio = [\n",
    "#    'numero', 'ley', 'leyes',\n",
    "#    'nacional', 'modificacion',\n",
    "#    'articulo', 'creacion', 'derogacion',\n",
    "#    'regimen', 'declarese', 'promulgacion',\n",
    "#    'expediente','codigo','nacion',\n",
    "#    'ano','modificaciones','bis',\n",
    "#    'incorporacion','programa','decreto','decretos',\n",
    "#    'articulos','nacion'\n",
    "#    ]  \n",
    "#for word in stopwords_dominio:\n",
    "#    STOP_WORDS.add(word)\n",
    "    \n",
    "#texto_df['Título normalizado'] = texto_df['Título normalizado'].apply(lambda x: ' '.join([word for word in x.split() if word not in (stopwords_dominio)]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a886af4-1152-4ed8-aa40-80e9ece45f33",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "with open('texto_df_ley_0923.pkl', 'wb') as file:\n",
    "    pickle.dump(texto_df,file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b377cc56-2516-4081-b15c-fe2b6237c1f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lo guardamos de nuevo\n",
    "#pickle.dump(texto_df, open('./texto_df_ley_1023.pkl', 'wb'))\n",
    "#texto_df = pickle.load(open('texto_df_ley_1023.pkl', 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "421ca46f-e64d-433c-b1f3-0738a3a07444",
   "metadata": {},
   "outputs": [],
   "source": [
    "texto_df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a842b362-1ca6-491a-b5fe-056cfa6b1f8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Librerias para texto\n",
    "import gensim\n",
    "from gensim.corpora import Dictionary\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a7cfafe-f332-4fd9-b9bd-063cc4b69400",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tokenizamos\n",
    "corpus_norm = list(texto_df['Título normalizado'].values)\n",
    "documentos_tokens = [docu.split() for docu in corpus_norm]\n",
    "\n",
    "diccionario = Dictionary(documentos_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9dcf69d-d024-4386-8148-41fbeaa3ba91",
   "metadata": {},
   "outputs": [],
   "source": [
    "diccionario"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bbc5f47-ae67-4a36-9666-b7298b9590f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Diccionario\n",
    "print('Diccionario Inicial: ', len(diccionario))\n",
    "print(format(diccionario))\n",
    "\n",
    "# Diccionario con más de 3 palabras (media) y con presencia de 20%\n",
    "diccionario.filter_extremes(no_below=3, no_above=0.2)\n",
    "diccionario.compactify()\n",
    "print('Diccionario Filtrado: ', len(diccionario))\n",
    "#print(dictionary.token2id)\n",
    "\n",
    "# Creamos la Bolsa de Palabras\n",
    "BoW_corpus = [diccionario.doc2bow(doc) for doc in documentos_tokens]\n",
    "print('\\nPrimer Documento del Corpus:\\n{}'.format(BoW_corpus[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2643a381-ad92-4145-9064-35df747c153c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Guardamos\n",
    "pickle.dump(diccionario, open(\"diccionario_ley_0923.pkl\", \"wb\"))\n",
    "pickle.dump(BoW_corpus, open('BoW_corpus_ley_0923.pkl', 'wb'))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8b01641-cb10-4b2d-bb1d-f3c562755672",
   "metadata": {},
   "source": [
    "#### Term Frequency-Inverse Document Frequency (TF-IDF)\n",
    "\n",
    "El TF-IDF (Frecuencia de Termino - Frecuencia Inversa de Documento) es una medida numérica que permite expresar como de relevante es una palabra para un documento en una colección de documentos (o corpus).\n",
    "\n",
    "Construir la Bolsa de Palabras con TF-IDF en vez de con frecuencias evita dar \"importancia\" a texto muy largos y con mucha repetición de palabras, frente a textos cortos y con pocas repeticiones de palabras.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47db8d11-fc0b-4bab-961b-520ad24a117f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import TfidfModel\n",
    "\n",
    "# Creamos la Bolsa de Palabras con TF-ID\n",
    "#BoW_corpus = [dictionary.doc2bow(doc) for doc in documents]\n",
    "tfidf = TfidfModel(BoW_corpus, smartirs='ntc')\n",
    "tfidf_corpus  = [tfidf[diccionario.doc2bow(doc)] for doc in documentos_tokens]\n",
    "\n",
    "# Resultados\n",
    "print('Diccionario de palabras -> palabra: id\\n')\n",
    "#print(dictionary_tfidf.token2id)\n",
    "print('\\nApariciones de las palabras en los documentos (id, tfidf):')\n",
    "#tfidf_corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e5c09a7-20fc-478b-972a-46b7c39e1216",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Guardamos\n",
    "pickle.dump(tfidf_corpus, open('tfidf_corpus_ley_0923.pkl', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a29363ef-d4c6-4384-9b44-55e939350c79",
   "metadata": {},
   "outputs": [],
   "source": [
    "# PARA VER palabras\n",
    "filtro_texto_df = pd.merge(texto_df,proyecto_2009_2024_df_LIMPIO[['Proyecto.ID','Proyecto_girado_a_comisiones_SALUD','Proyecto_SALUD','Resultado','Max_Orden','Tiene_antecedente_por_titulo_proy','Periodo']], how = 'inner',left_on = 'Proyecto.ID', right_on='Proyecto.ID' )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85b30612-11a9-4188-990d-9957062a13b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "filtro_texto_df['Tokens'] = filtro_texto_df['Título normalizado'].apply(lambda x: x.split()) #list of lists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d57ab035-44c5-4dc4-bf18-30142637db0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "filtro_texto_df[['Título','Tokens']].head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "480a0fef-4e40-4b34-a10d-8f809af63495",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Para entender mejor un diccionario de palabras con peso por tf idf\n",
    "# https://weiliu2k.github.io/CITS4012/gensim/tf-idf.html\n",
    "# https://github.com/simplykeerthana/WordCloud-Generator/blob/main/word_cloud_gen.ipynb\n",
    "\n",
    "\n",
    "def get_dict_to_wordcloud(documents1,dictionary):\n",
    "    dic = {}\n",
    "    for i, doc in enumerate(documents1):\n",
    "        for idx, freq in tfidf[dictionary.doc2bow(doc)]:\n",
    "            key = dictionary[idx]\n",
    "            if key in dic:\n",
    "                dic[key] += np.around(freq,decimals=2)\n",
    "            else:\n",
    "                dic[key] = np.around(freq,decimals=2)\n",
    "    return dic\n",
    "                \n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b03aba62-a15c-48e4-9d72-6b487008164b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from wordcloud import WordCloud\n",
    "import matplotlib.pyplot as plt\n",
    "import itertools\n",
    "%matplotlib inline\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92b15eb4-0523-416b-a3f2-e62640703834",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Todo\n",
    "dic_all = get_dict_to_wordcloud(documentos_tokens,diccionario)\n",
    "\n",
    "# Salud\n",
    "documentos_tokens_temp = list(filtro_texto_df[filtro_texto_df['Proyecto_SALUD']==1]['Tokens'])\n",
    "dic_salud = get_dict_to_wordcloud(documentos_tokens_temp,diccionario)\n",
    "\n",
    "# Otras\n",
    "documentos_tokens_temp = list(filtro_texto_df[filtro_texto_df['Proyecto_SALUD']==0]['Tokens'])\n",
    "dic_otras = get_dict_to_wordcloud(documentos_tokens_temp,diccionario)\n",
    "\n",
    "words_comisiones = {\n",
    "    ' Todos los IL': dic_all,\n",
    "    'IL de Salud (girada a primera instancia a comisiones con la palabra Salud en su nombre)': dic_salud,\n",
    "    'IL otro (girada a primera instancia a otras comisiones sin la palabra Salud en su nombre)':dic_otras\n",
    "}\n",
    "\n",
    "plt.figure(figsize=(25, 20))\n",
    "pos = 1\n",
    "for key, words in words_comisiones.items():\n",
    "    plt.subplot(3, 1, pos)\n",
    "    wordcloud = WordCloud(max_font_size=80, max_words=100, background_color=\"white\").fit_words(words)\n",
    "    plt.imshow(wordcloud, interpolation='bilinear')\n",
    "    plt.axis(\"off\")\n",
    "    plt.title(\"Palabras presentes en títulos de Iniciativas Legislativa(IL) asociadas a proyecto de Ley {}\".format(key.upper()))\n",
    "    pos += 1\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00f6eb0b-aad1-46d3-a15a-84898ae57c77",
   "metadata": {},
   "source": [
    "¿Qué proyectos que no pasaron en primera instancia por comisión de Salud, tiene asociado la palabra reproducción?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23b38f5a-bb2e-45eb-998e-ea7f4a3d1759",
   "metadata": {},
   "outputs": [],
   "source": [
    "filtro_texto_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e396fd19-e810-4ebe-b906-a5263cbd7611",
   "metadata": {},
   "outputs": [],
   "source": [
    "reprod_df = filtro_texto_df.loc[(filtro_texto_df['Proyecto_SALUD']==0) & (filtro_texto_df['Título normalizado'].str.contains('reproduccion')== True),['Proyecto.ID', 'Título','Tokens','Proyecto_SALUD','Proyecto_girado_a_comisiones_SALUD']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95731780-4aef-49bc-8794-76f9534fc3c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "reprod_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a09142bd-92fb-4e95-b62b-3c6a07052e48",
   "metadata": {},
   "outputs": [],
   "source": [
    "reprod_df.describe(include = 'all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fcddbdf-9719-4dc9-a455-2d94d45b2d35",
   "metadata": {},
   "outputs": [],
   "source": [
    "girocom_df = pd.read_csv('diputados/giroacomisiones2.0.csv')\n",
    "print('Tamaño de dataset de Giro a comisiones:',girocom_df.shape)\n",
    "display(girocom_df.head(2))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "670445ad-2cc5-4c6b-9139-54c77b0dbc5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "reprod_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "224f1ac1-2905-4826-89f3-a9fc828e42c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "temp = pd.merge(reprod_df[reprod_df['Proyecto_girado_a_comisiones_SALUD'].str.contains('GIRADO A OTRAS COMISIONES')],girocom_df[girocom_df['Orden']==1], how='inner', on= 'Proyecto.ID')\n",
    "temp.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b3bbafc-397d-42a0-944b-5b3ac69ed676",
   "metadata": {},
   "outputs": [],
   "source": [
    "temp.head(6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7484cfd-aaf2-4a1f-805c-b00290732521",
   "metadata": {},
   "outputs": [],
   "source": [
    "temp[temp['Proyecto_girado_a_comisiones_SALUD'].str.contains('GIRADO A OTRAS COMISIONES')]['Comisión'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60ca209c-d28f-4570-b16c-b587047ae0b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "temp[temp['Comisión'].str.contains('FAMILIA, MUJER, NIÑEZ Y ADOLESCENCIA')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5244e534-4f49-42f6-a063-c2d862945229",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Todo\n",
    "dic_all = get_dict_to_wordcloud(documentos_tokens,diccionario)\n",
    "\n",
    "# Salud\n",
    "documentos_tokens_temp = list(filtro_texto_df[filtro_texto_df['Proyecto_girado_a_comisiones_SALUD']=='GIRADO A COMISIONES DE SALUD']['Tokens'])\n",
    "dic_salud = get_dict_to_wordcloud(documentos_tokens_temp,diccionario)\n",
    "\n",
    "# Otras\n",
    "documentos_tokens_temp = list(filtro_texto_df[filtro_texto_df['Proyecto_girado_a_comisiones_SALUD']=='GIRADO A OTRAS COMISIONES']['Tokens'])\n",
    "dic_otras = get_dict_to_wordcloud(documentos_tokens_temp,diccionario)\n",
    "\n",
    "words_comisiones = {\n",
    "    ' Todos los IL': dic_all,\n",
    "    'IL girado a comisiones de Salud ': dic_salud,\n",
    "    'IL girado a otras comisiones':dic_otras\n",
    "}\n",
    "\n",
    "plt.figure(figsize=(25, 20))\n",
    "pos = 1\n",
    "for key, words in words_comisiones.items():\n",
    "    plt.subplot(3, 1, pos)\n",
    "    wordcloud = WordCloud(max_font_size=80, max_words=100, background_color=\"white\").fit_words(words)\n",
    "    plt.imshow(wordcloud, interpolation='bilinear')\n",
    "    plt.axis(\"off\")\n",
    "    plt.title(\"Palabras presentes en títulos de Iniciativas Legislativa(IL) asociadas a proyecto de Ley {}\".format(key.upper()))\n",
    "    pos += 1\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71e10d42-45b0-4e0d-a320-d03613b71561",
   "metadata": {},
   "source": [
    "### Común vocabulario por periodo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78ad7920-632d-480c-b6da-ea4d3990d632",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Guardar - OJO CON LOS REGISTROS SIN PERIODO\n",
    "pickle.dump(filtro_texto_df, open('filtro_texto_df_ley_0923.pkl', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2095011-c921-48c9-a298-43767d7542d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Agrupar titulos por periodo\n",
    "periodo_salud_original_df = filtro_texto_df[filtro_texto_df['Proyecto_SALUD']==1].groupby('Periodo')['Título'].apply(lambda x: ' '.join(x)).reset_index()\n",
    "periodo_salud_normalizado_df = filtro_texto_df[filtro_texto_df['Proyecto_SALUD']==1].groupby('Periodo')['Título normalizado'].apply(lambda x: ' '.join(x)).reset_index()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff569b2d-385a-4444-b959-02a767e14add",
   "metadata": {},
   "outputs": [],
   "source": [
    "periodo_salud_original_df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e693ce4c-70c8-4978-ac8e-13272ad073a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def paso_uno_pares(lista_items):\n",
    "    return [(lista_items[i],lista_items[i+1]) for i in range(len(lista_items)-1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2529a5c7-48df-4907-adef-ba5713b4148b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ordenar períodos según el número \n",
    "periodos = sorted(periodo_salud_original_df['Periodo'].to_list())\n",
    "periodo_pares = paso_uno_pares(periodos)\n",
    "print(periodo_pares)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "177e5652-a5d9-4e24-8246-48e632513150",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_tokens(text):\n",
    "    \"\"\"\n",
    "    Función que dado un texto devuelve una lista con las palabras del texto no vacias\n",
    "    \"\"\"\n",
    "    doc = nlp(text)\n",
    "    return [word.text for word in doc]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f63f49dc-30bd-4580-b08c-bd743cf35cb3",
   "metadata": {},
   "source": [
    "#### Calcular la intersección de vocabulario/token entre pares de períodos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b341c0e-3dd6-400e-8b0a-24a58bc94cb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sobre titulos sin limpieza\n",
    "periodo_salud_original_df['vocab'] = periodo_salud_original_df['Título'].str.lower()\n",
    "periodo_salud_original_df['vocab'] = periodo_salud_original_df['vocab'].apply(get_tokens)\n",
    "comun_vocab_list = []\n",
    "\n",
    "for par in periodo_pares:\n",
    "    \n",
    "    s1 = set(periodo_salud_original_df.loc[(periodo_salud_original_df.Periodo==par[0])].vocab.values[0])\n",
    "    s2 = set(periodo_salud_original_df.loc[(periodo_salud_original_df.Periodo==par[1])].vocab.values[0])\n",
    "    comun_vocab = len(s1.intersection(s2))\n",
    "    comun_vocab_list.append([par, comun_vocab])\n",
    "    \n",
    "comun_vocab_salud_original_df = pd.DataFrame(comun_vocab_list, columns = ['par', 'comun_vocab'])\n",
    "# comun_vocabab_df_original.to_csv('../out_files/comun_vocabab_df_original.csv', index=False)\n",
    "print(comun_vocab_salud_original_df.head(2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "485f4e36-592c-46b7-b642-7b29e791ab75",
   "metadata": {},
   "outputs": [],
   "source": [
    "comun_vocab_salud_original_df.to_csv('./archivos_salidas/comun_vocab_salud_original.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffb005fd-4a51-4de8-b4e3-5c72f2163a0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "periodo_salud_normalizado_df['vocab'] = periodo_salud_normalizado_df['Título normalizado'].apply(get_tokens)\n",
    "comun_vocab_norm_list = []\n",
    "\n",
    "for par in periodo_pares:\n",
    "    \n",
    "    s1 = set(periodo_salud_normalizado_df.loc[(periodo_salud_normalizado_df.Periodo==par[0])].vocab.values[0])\n",
    "    s2 = set(periodo_salud_normalizado_df.loc[(periodo_salud_normalizado_df.Periodo==par[1])].vocab.values[0])\n",
    "    comun_vocab = len(s1.intersection(s2))\n",
    "    comun_vocab_norm_list.append([par, comun_vocab])\n",
    "    \n",
    "comun_vocab_salud_norm_df = pd.DataFrame(comun_vocab_norm_list, columns = ['par', 'comun_vocab'])\n",
    "# comun_vocabab_df_original.to_csv('../out_files/comun_vocabab_df_original.csv', index=False)\n",
    "print(comun_vocab_salud_norm_df.head(2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56f89994-d8a9-4077-8690-7107b08613bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "comun_vocab_salud_norm_df.to_csv('./archivos_salidas/comun_vocab_salud_norm.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59c09d0e-ab4f-4969-82e3-c3f15f99e0dc",
   "metadata": {},
   "source": [
    "#### Visualizar vocabulario común"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b945acb-ed6d-42d6-a5f3-0ad44f53ab40",
   "metadata": {},
   "outputs": [],
   "source": [
    "periodos = {\n",
    "    127: (2009, 2010),\n",
    "    128: (2010, 2011),\n",
    "    129: (2011, 2012),\n",
    "    130: (2012, 2013),\n",
    "    131: (2013, 2014),\n",
    "    132: (2014, 2015),\n",
    "    133: (2015, 2016),\n",
    "    134: (2016, 2017),\n",
    "    135: (2017, 2018),\n",
    "    136: (2018, 2019),\n",
    "    137: (2019, 2020),\n",
    "    138: (2020, 2021),\n",
    "    139: (2021, 2022),\n",
    "    140: (2022, 2023)\n",
    "}\n",
    "\n",
    "comun_vocab_salud_original_df['version'] = 'Sin procesamiento'\n",
    "comun_vocab_salud_original_df['Periodo inicio'] = comun_vocab_salud_original_df['par'].map(lambda x: periodos[x[0]][0])\n",
    "comun_vocab_salud_original_df['Periodo fin'] = comun_vocab_salud_original_df['par'].map(lambda x: periodos[x[1]][1])\n",
    "comun_vocab_salud_original_df['Periodo intermedio'] = ((comun_vocab_salud_original_df['Periodo inicio'] \n",
    "                                        + comun_vocab_salud_original_df['Periodo fin']) / 2)\n",
    "\n",
    "comun_vocab_salud_norm_df['version'] = 'Con procesamiento'\n",
    "comun_vocab_salud_norm_df['Periodo inicio'] = comun_vocab_salud_norm_df['par'].map(lambda x: periodos[x[0]][0])\n",
    "comun_vocab_salud_norm_df['Periodo fin'] = comun_vocab_salud_norm_df['par'].map(lambda x: periodos[x[1]][1])\n",
    "comun_vocab_salud_norm_df['Periodo intermedio'] = ((comun_vocab_salud_norm_df['Periodo inicio'] \n",
    "                                        + comun_vocab_salud_norm_df['Periodo fin']) / 2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "124bd749-7cf9-4b08-96bf-bf202ec2b45e",
   "metadata": {},
   "outputs": [],
   "source": [
    "todas_versiones_df = pd.concat([comun_vocab_salud_original_df,comun_vocab_salud_norm_df], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "677e2679-1783-4517-844e-da2184c0bbae",
   "metadata": {},
   "outputs": [],
   "source": [
    "todas_versiones_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c20626d-8047-4848-8437-4369b53fb58f",
   "metadata": {},
   "outputs": [],
   "source": [
    "todas_versiones_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9e8843c-4cc5-4cbc-b1b3-9f92f317e093",
   "metadata": {},
   "outputs": [],
   "source": [
    "todas_versiones_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e44ba670-8b12-4673-b745-7a006b6694b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def periodos_a_fechas(periodos):\n",
    "\n",
    "    period_dict = {\n",
    "                  127:'01/03/2009-28/02/2010',\n",
    "                  128:'01/03/2010-28/02/2011',\n",
    "                  129:'01/03/2011-29/02/2012',\n",
    "                  130:'01/03/2012-28/02/2013',\n",
    "                  131:'01/03/2013-28/02/2014',\n",
    "                  132:'01/03/2014-28/02/2015',\n",
    "                  133:'01/03/2015-29/02/2016',\n",
    "                  134:'01/03/2016-28/02/2017',\n",
    "                  135:'01/03/2017-28/02/2018',\n",
    "                  136:'01/03/2018-28/02/2019',\n",
    "                  137:'01/03/2019-29/02/2020', \n",
    "                  138:'01/03/2020-28/02/2021', \n",
    "                  139:'01/03/2021-28/02/2022',\n",
    "                  140:'01/03/2022-28/02/2023'}\n",
    "    \n",
    "    if isinstance(periodos, tuple):\n",
    "#         return r\"$\\bf{\" + str(periods[0]) + \"\\ &\\ \" +str(periods[1]) + \"}$\" + \"\\n\" +period_dict[periods[0]]+' &\\n '+period_dict[periods[1]]\n",
    "        return f'{str(periodos[0])} ({period_dict[periodos[0]]}) &\\n {str(periodos[1])} ({period_dict[periodos[1]]})'\n",
    "\n",
    "    else:\n",
    "        return r\"$\\bf{\" + 'Period\\ '+ str(periodos)+ \"}$\"+'\\n'+period_dict[periodos]        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f75444c8-877a-4b06-9aa5-e3702e1c8e8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib.font_manager import FontProperties\n",
    "from matplotlib.ticker import FuncFormatter\n",
    "from numerize import numerize \n",
    "\n",
    "\n",
    "fig = plt.figure(figsize=(15, 6))\n",
    "colors = sns.color_palette(\"hls\", 90) #90 is available pairs\n",
    "\n",
    "plt.rcParams.update({'font.size': 12})\n",
    "\n",
    "versions = list(set(todas_versiones_df.version.to_list()))\n",
    "                \n",
    "for version in versions:\n",
    "    \n",
    "    Y = todas_versiones_df.loc[(todas_versiones_df['version']==version)].comun_vocab.to_list()\n",
    "    X = todas_versiones_df.loc[(todas_versiones_df['version']==version)]['Periodo intermedio'].to_list()\n",
    "\n",
    "    plt.plot(X,Y, marker=\"o\")\n",
    "\n",
    "\n",
    "xticks = comun_vocab_salud_original_df['Periodo intermedio'].unique()\n",
    "xtick_labels = [ periodos_a_fechas(x) for x in sorted(comun_vocab_salud_original_df['par'].unique()) ]\n",
    "\n",
    "plt.xlabel('Pares de Períodos Parlamentarios', fontsize=18, labelpad=140)\n",
    "plt.ylabel('Número común de palabras(tokens)', fontsize=16)\n",
    "\n",
    "ax = plt.gca()\n",
    "ax.set_ylim([0,1000])\n",
    "handles, labels = ax.get_legend_handles_labels()\n",
    "formatter = FuncFormatter(numerize.numerize)\n",
    "ax.yaxis.set_major_formatter(formatter)\n",
    "plt.title('Vocabulario común entre pares de períodos', fontsize=20)\n",
    "plt.legend(versions, loc='upper right',prop={'size': 14})\n",
    "\n",
    "for i, xtick in enumerate(xticks):\n",
    "    plt.annotate(xtick_labels[i], fontsize=11, annotation_clip=False,  rotation=40,  xy=(xtick, -0.5), ma='center', xytext=(xtick-2,-450))\n",
    "  \n",
    "    \n",
    "#hide major xticks\n",
    "plt.tick_params(axis='x', which='major', bottom=False, top=False, labelbottom=False)\n",
    "\n",
    "plt.savefig('./archivos_salidas/comun_vocab.png')\n",
    "plt.tight_layout(pad=2)\n",
    "plt.subplots_adjust(bottom=0.2)\n",
    "plt.show()\n",
    "plt.cla()\n",
    "plt.clf()\n",
    "fig.clear()\n",
    "\n",
    "plt.close(fig)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e1ab186-4759-4391-9c41-86be7c065e2d",
   "metadata": {},
   "source": [
    "#### Métricas promedio para cada período parlamentario antes del preprocesamiento, después del preprocesamiento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cead726-599d-4695-9c23-6b8be3d56837",
   "metadata": {},
   "outputs": [],
   "source": [
    "### IL de salud publicadas entres 2010-2023\n",
    "filtro_texto_df[filtro_texto_df['Proyecto_SALUD']==1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc866909-8c10-43f5-a633-8a6563764cd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "periodo_salud_normalizado_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d373a6b-96c8-447d-83e1-3f5d150d1417",
   "metadata": {},
   "outputs": [],
   "source": [
    "metricas ={ 'Sin procesamiento': {\n",
    " 'Cantidad promedio de palabras': round(periodo_salud_original_df['vocab'].apply(lambda x : len(x)).sum()/periodo_salud_original_df.shape[0],0),\n",
    " 'Cantidad promedio de palabras únicas': round(len(set(periodo_salud_original_df.vocab.values[0]))/periodo_salud_original_df.shape[0],0) },\n",
    " 'Con procesamiento': {\n",
    " 'Cantidad promedio de palabras': round(periodo_salud_normalizado_df['vocab'].apply(lambda x : len(x)).sum()/periodo_salud_normalizado_df.shape[0],0),\n",
    " 'Cantidad promedio de palabras únicas': round(len(set(periodo_salud_normalizado_df.vocab.values[0]))/periodo_salud_normalizado_df.shape[0],0)}}\n",
    "metricas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f62c2838-a865-4881-b0bf-3dd434dd715a",
   "metadata": {},
   "outputs": [],
   "source": [
    "metrica_df = pd.DataFrame.from_dict(metricas, orient= 'index')\n",
    "metrica_df.to_csv('./archivos_salidas/metrica_vocab_salud.csv', index=False)\n",
    "metrica_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43521631-0473-44f0-94f6-b368fa8731bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "filtro_texto_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11808a89-ada3-45df-b0b7-b89bee1c45fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "proyecto_2009_2024_df_LIMPIO.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9196be4b-8c3f-40d7-9909-59096119820c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#filtro_texto_df = filtro_texto_df = pd.merge(filtro_texto_df,proyecto_2009_2024_df_LIMPIO[['Proyecto.ID','Publicación.Fecha','Año','Duración_dias_prep']], how = 'inner',left_on = 'Proyecto.ID', right_on='Proyecto.ID' )\n",
    "# Guardar\n",
    "#pickle.dump(filtro_texto_df, open('filtro_texto_df_ley_1023.pkl', 'wb'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv_IL",
   "language": "python",
   "name": "myenv_il"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
