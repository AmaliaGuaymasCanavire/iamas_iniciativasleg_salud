{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a5ec4dc1-39a2-4728-b9a5-81e3419ba3f5",
   "metadata": {},
   "source": [
    "# 4.2 Evaluar cuantitativamente y cualitativamente algoritmos para detectar cambio sem√°ntico\n",
    "\n",
    "Se evaluaran Orthogonal Procrustes ,Second-Order Similarity Y NN (Nearest Neighbors) para detectar ara detectar cambios en el significado de las palabras en los t√≠tulos de IL a lo largo de los a√±os 2010 - 2023.\n",
    "\n",
    "Ver si es as√≠\n",
    "* Si buscas estabilidad y comparabilidad: Orthogonal Procrustes es la mejor opci√≥n.\n",
    "* Si quieres capturar cambios m√°s sutiles: Second-Order Similarity es m√°s adecuado.\n",
    "* Si te interesa la interpretaci√≥n basada en contexto: Compass es una buena elecci√≥n.\n",
    "* Si prefieres una detecci√≥n simple y efectiva: NN (Nearest Neighbors) es f√°cil de aplicar.\n",
    "\n",
    "üìå Consideraciones antes de aplicar los m√©todos\n",
    "* 1Ô∏è‚É£ Tama√±o del corpus: Si el per√≠odo 2020-2024 tiene menos datos, es posible que el an√°lisis de cambio sem√°ntico sea m√°s ruidoso. Puedes compensarlo con t√©cnicas de normalizaci√≥n o usando menos palabras con baja frecuencia.\n",
    "* 2Ô∏è‚É£ Alineaci√≥n temporal: Debes alinear los embeddings de manera secuencial (2010-2015 ‚Üí 2015-2020 ‚Üí 2020-2024) usando Orthogonal Procrustes o Compass.\n",
    "* 3Ô∏è‚É£ Comparaci√≥n estable: Para evitar sesgos, podr√≠as analizar cambios entre per√≠odos completos (2010-2020) y luego comparar con el per√≠odo incompleto (2020-2024).\n",
    "* 4Ô∏è‚É£ Intersecci√≥n de vocabulario: Eliminar palabras con muy baja frecuencia en el per√≠odo 2020-2024 para evitar palabras con embeddings inestables.\n",
    "*  Comparar con per√≠odos combinados: Puedes comparar 2010-2020 vs. 2020-2024 para ver si los cambios en el √∫ltimo per√≠odo son significativos.\n",
    "\n",
    "### Papers recientes sobre cambio sem√°ntico\n",
    "* Hamilton et al. (2016) - \"Diachronic Word Embeddings Reveal Statistical Laws of Semantic Change\"\n",
    "    * https://aclanthology.org/P16-1141/\n",
    "    * Introduce Orthogonal Procrustes para alinear embeddings.\n",
    "\n",
    "* Gonen et al. (2020) - \"Simple, Interpretable and Stable Method for Detecting Words with Usage Change across Corpora\"\n",
    "    * https://aclanthology.org/2020.acl-main.51/\n",
    "    * Introduce el m√©todo basado en vecinos m√°s cercanos (NN).\n",
    "\n",
    "* Montariol et al. (2021) - \"Scalable and Interpretable Semantic Change Detection\"\n",
    "    * https://aclanthology.org/2021.naacl-main.369/\n",
    "    * Combina varios m√©todos para mejorar la detecci√≥n de cambio sem√°ntico\n",
    "      \n",
    "      \n",
    "* Dritsa1 et al. (2022) - \"A Greek Parliament Proceedings Dataset for Computational Linguistics and Political Analysis\"\n",
    "    * El paper analiza el cambio sem√°ntico en discursos parlamentarios y compara cuatro enfoques principales para detectar cambios en el significado de palabras a lo largo del tiempo.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9a7be913-4337-41de-884b-fb09b538db3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importar librerias\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "import sweetviz as sv\n",
    "\n",
    "# Visualizaci√≥n\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "from matplotlib.lines import Line2D\n",
    "import matplotlib.colors as mcolors\n",
    "from matplotlib import colormaps\n",
    "\n",
    "\n",
    "from tqdm import tqdm\n",
    "tqdm.pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5f753f71-40b3-442b-9810-0449008f6ebb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configurar path\n",
    "os.chdir('C://iamas_datos2024/proyectos_parlamentarios_2025/')\n",
    "pd.set_option('display.max_colwidth', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b372f921-2291-4b31-becd-55e1d3caa1b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Abrir\n",
    "df = pickle.load(open('filtro_texto_df_ley_1023.pkl', 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e2ed965d-c790-4c4a-b312-322f1045139f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Proyecto.ID</th>\n",
       "      <th>T√≠tulo</th>\n",
       "      <th>T√≠tulo normalizado</th>\n",
       "      <th>Proyecto_girado_a_comisiones_SALUD</th>\n",
       "      <th>Proyecto_SALUD</th>\n",
       "      <th>Resultado</th>\n",
       "      <th>Max_Orden</th>\n",
       "      <th>Tiene_antecedente_por_titulo_proy</th>\n",
       "      <th>Periodo</th>\n",
       "      <th>Tokens</th>\n",
       "      <th>Publicaci√≥n.Fecha</th>\n",
       "      <th>A√±o</th>\n",
       "      <th>Duraci√≥n_dias_prep</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>HCDN272363</td>\n",
       "      <td>DECLARESE EL 2024 COMO A√ëO DEL 140 ANIVERSARIO DE LA PROMULGACION DE LA LEY 1420 DE EDUCACION COMUN.</td>\n",
       "      <td>declarese aniversario promulgacion educacion comun</td>\n",
       "      <td>GIRADO A OTRAS COMISIONES</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NO TUVO TRATAMIENTO POSTERIOR NI DICTAMEN</td>\n",
       "      <td>2</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[declarese, aniversario, promulgacion, educacion, comun]</td>\n",
       "      <td>2023-12-29</td>\n",
       "      <td>2023</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>HCDN272359</td>\n",
       "      <td>FINANCIAMIENTO DE LOS PARTIDOS POLITICOS - LEY 26215 - Y CODIGO ELECTORAL NACIONAL - LEY 19945 -. MODIFICACIONES SOBRE CONTRATACION DE PUBLICIDAD Y BOLETA UNICA, RESPECTIVAMENTE.</td>\n",
       "      <td>financiamiento partidos politicos electoral nacional modificaciones contratacion publicidad boleta unica respectivamente</td>\n",
       "      <td>GIRADO A OTRAS COMISIONES</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NO TUVO TRATAMIENTO POSTERIOR NI DICTAMEN</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[financiamiento, partidos, politicos, electoral, nacional, modificaciones, contratacion, publicidad, boleta, unica, respectivamente]</td>\n",
       "      <td>2023-12-28</td>\n",
       "      <td>2023</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Proyecto.ID  \\\n",
       "0  HCDN272363   \n",
       "1  HCDN272359   \n",
       "\n",
       "                                                                                                                                                                               T√≠tulo  \\\n",
       "0                                                                                DECLARESE EL 2024 COMO A√ëO DEL 140 ANIVERSARIO DE LA PROMULGACION DE LA LEY 1420 DE EDUCACION COMUN.   \n",
       "1  FINANCIAMIENTO DE LOS PARTIDOS POLITICOS - LEY 26215 - Y CODIGO ELECTORAL NACIONAL - LEY 19945 -. MODIFICACIONES SOBRE CONTRATACION DE PUBLICIDAD Y BOLETA UNICA, RESPECTIVAMENTE.   \n",
       "\n",
       "                                                                                                         T√≠tulo normalizado  \\\n",
       "0                                                                        declarese aniversario promulgacion educacion comun   \n",
       "1  financiamiento partidos politicos electoral nacional modificaciones contratacion publicidad boleta unica respectivamente   \n",
       "\n",
       "  Proyecto_girado_a_comisiones_SALUD  Proyecto_SALUD  \\\n",
       "0          GIRADO A OTRAS COMISIONES             0.0   \n",
       "1          GIRADO A OTRAS COMISIONES             0.0   \n",
       "\n",
       "                                   Resultado  Max_Orden  \\\n",
       "0  NO TUVO TRATAMIENTO POSTERIOR NI DICTAMEN          2   \n",
       "1  NO TUVO TRATAMIENTO POSTERIOR NI DICTAMEN          1   \n",
       "\n",
       "   Tiene_antecedente_por_titulo_proy  Periodo  \\\n",
       "0                              False      NaN   \n",
       "1                              False      NaN   \n",
       "\n",
       "                                                                                                                                 Tokens  \\\n",
       "0                                                                              [declarese, aniversario, promulgacion, educacion, comun]   \n",
       "1  [financiamiento, partidos, politicos, electoral, nacional, modificaciones, contratacion, publicidad, boleta, unica, respectivamente]   \n",
       "\n",
       "  Publicaci√≥n.Fecha   A√±o  Duraci√≥n_dias_prep  \n",
       "0        2023-12-29  2023                -1.0  \n",
       "1        2023-12-28  2023                -1.0  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e4ab9fab-fc6c-4f52-87b3-5caeefd16463",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 31334 entries, 0 to 31333\n",
      "Data columns (total 13 columns):\n",
      " #   Column                              Non-Null Count  Dtype         \n",
      "---  ------                              --------------  -----         \n",
      " 0   Proyecto.ID                         31334 non-null  category      \n",
      " 1   T√≠tulo                              31334 non-null  category      \n",
      " 2   T√≠tulo normalizado                  31334 non-null  object        \n",
      " 3   Proyecto_girado_a_comisiones_SALUD  31334 non-null  category      \n",
      " 4   Proyecto_SALUD                      31334 non-null  float64       \n",
      " 5   Resultado                           31334 non-null  category      \n",
      " 6   Max_Orden                           31334 non-null  int64         \n",
      " 7   Tiene_antecedente_por_titulo_proy   31334 non-null  bool          \n",
      " 8   Periodo                             29781 non-null  float64       \n",
      " 9   Tokens                              31334 non-null  object        \n",
      " 10  Publicaci√≥n.Fecha                   31334 non-null  datetime64[ns]\n",
      " 11  A√±o                                 31334 non-null  int32         \n",
      " 12  Duraci√≥n_dias_prep                  31334 non-null  float64       \n",
      "dtypes: bool(1), category(4), datetime64[ns](1), float64(3), int32(1), int64(1), object(2)\n",
      "memory usage: 3.4+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3ede60a4-c98b-4062-b566-ea3f49a3fbd1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Conj. de datos de proyecto_SALUD con Nan en Per√≠odo: (2692, 13)\n",
      "Conj. de datos de proyecto_SALUD sin Nan en Per√≠odo: (2562, 13)\n"
     ]
    }
   ],
   "source": [
    "df = df[df['Proyecto_SALUD']==1]\n",
    "print(\"Conj. de datos de proyecto_SALUD con Nan en Per√≠odo:\",df.shape)\n",
    "df = df[~df['Periodo'].isna()]\n",
    "print(\"Conj. de datos de proyecto_SALUD sin Nan en Per√≠odo:\",df.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9bce733-c31f-4c00-a774-90b2cd926e17",
   "metadata": {},
   "source": [
    "###  Cargar Corpus para los tres per√≠odos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8da375c1-cfcc-449d-82a8-83c6c51b9f77",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Periodo_5anios'] = 2010\n",
    "df.loc[(df['A√±o']>=2015) & (df['A√±o']<2020), 'Periodo_5anios'] =  2015\n",
    "df.loc[(df['A√±o']>=2020) & (df['A√±o']<2024), 'Periodo_5anios'] =  2020"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "01275bfb-0be9-47a1-9ba0-2a8cf91c20e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3/3 [00:00<00:00, 3004.52it/s]\n",
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3/3 [00:00<00:00, 1175.42it/s]\n",
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3/3 [00:00<00:00, 2996.64it/s]\n"
     ]
    }
   ],
   "source": [
    "#concat sentences, each last sentence for each speech did not have dot so add one.\n",
    "PER5anios_df = df.groupby('Periodo_5anios')['T√≠tulo normalizado'].progress_apply('.'.join).reset_index() \n",
    "PER5anios_df['corpus']= PER5anios_df['T√≠tulo normalizado'].progress_apply(lambda x: [sent.split(' ') for sent in x.split('.')])\n",
    "PER5anios_df['corpus'] = PER5anios_df['corpus'].progress_apply(lambda x: [token for token in x if token!='' and token!=' '])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a30a122-e367-43d9-b4c9-915be4af3d9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Guardar el archivo binario proyecto\n",
    "with open('PER5anios_2025df.pkl', 'wb') as file:\n",
    "    pickle.dump(PER5anios_df,file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ecce853a-99cc-4a78-b975-f89f35de2ee6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['acciones',\n",
       "  'instituyase',\n",
       "  'julio',\n",
       "  'homenaje',\n",
       "  'nacimiento',\n",
       "  'doctor',\n",
       "  'rene',\n",
       "  'geronimo',\n",
       "  'favaloro'],\n",
       " ['cobertura', 'universal', 'salud', 'instituye', 'diciembre'],\n",
       " ['historias', 'clinicas', 'regimen']]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "PER5anios_df['corpus'][0][0:3]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b3d5235-e93b-4c19-871b-a5e6bfbfa108",
   "metadata": {},
   "source": [
    "## 1 -  Orthogonal Procrustes (Hamilton)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b9867f2b-e517-4ab5-baf1-6d438de9aeb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import Word2Vec\n",
    "import itertools\n",
    "from collections import defaultdict\n",
    "import re\n",
    "import random as rn\n",
    "import datetime\n",
    "from sklearn.metrics.pairwise import cosine_similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c2b2d751-f119-4fb4-b6d7-db598d3d50b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_cosine_similarity(model1,model2,word):\n",
    "    vector1 = model1.wv[word].reshape(1,-1)\n",
    "    vector2 = model2.wv[word].reshape(1,-1)\n",
    "    return(cosine_similarity(X=vector1, Y=vector2)[0][0])\n",
    "\n",
    "def step_one_pairs(list_of_items):\n",
    "    return [(list_of_items[i],list_of_items[i+1]) for i in range(len(list_of_items)-1)]\n",
    "\n",
    "tqdm.pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "93b51ae5-6751-4dc8-9434-cb32fbaea808",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuraci√≥n\n",
    "models_dir =  './archivos_salidas/modelos/hamilton_estabilidad/'\n",
    "run=0\n",
    "iterations=10\n",
    "diter=5\n",
    "siter=5\n",
    "vector_size=200 #\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "381f5817-fc11-47eb-a953-6af0bd9dfe21",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Periodo_5anios', 'T√≠tulo normalizado', 'corpus'], dtype='object')"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "PER5anios_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "98ae48bd-e1a2-41bf-8256-c03633814c9b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(2010, 2015), (2015, 2020)]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "if not os.path.exists(models_dir):\n",
    "    print('Creating models directory...')\n",
    "    os.makedirs(models_dir)\n",
    "    \n",
    "PER5anios_df.sort_values(by='Periodo_5anios')\n",
    "anios5_list = sorted(PER5anios_df['Periodo_5anios'].to_list())\n",
    "anios5_pairs = step_one_pairs(anios5_list)\n",
    "anios5_pairs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d87aeb91-210c-4a80-85e3-f189ef2396e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Funci√≥n para alinear embeddings\n",
    "def align_embeddings(base_model, target_model, shifts_PERanios5_list, i,periodo):\n",
    "    base_words = list(base_model.wv.index_to_key)\n",
    "    target_words = list(target_model.wv.index_to_key)\n",
    "    common_words = list(set(base_words) & set(target_words))\n",
    "    print('Common vocab length... ', str(len(common_words)))\n",
    "    print('Computing word similarity between ....')\n",
    "\n",
    "    for word in tqdm(common_words):\n",
    "        #union of neighbors in three points in time\n",
    "        neighbors_t1 = [w for w,s in base_model.wv.most_similar(positive=[word], topn=25)]\n",
    "        neighbors_t2 = [w for w,s in target_model.wv.most_similar(positive=[word], topn=25)]\n",
    "        neighbors_union = [n for n in list(set(neighbors_t1+neighbors_t2)) if n in common_words]\n",
    "        \n",
    "        # similarity vector for time point 1 (t1)\n",
    "        # each element is the cosine similarity of topic vector in t1 and each neighbor from neighbors_union\n",
    "        similarity_vector_t1 = []\n",
    "        word_vector_t1 = base_model.wv[word]\n",
    "        \n",
    "        for nn in neighbors_union:\n",
    "            neighbor_vector = base_model.wv[nn]\n",
    "            similarity_vector_t1.append(cosine_similarity(X=word_vector_t1.reshape(1,-1), Y=neighbor_vector.reshape(1,-1))[0][0])\n",
    "\n",
    "        # similarity vector for time point 2 (t2)\n",
    "        # each element is the cosine similarity of topic vector in t2 and each neighbor from neighbors_union\n",
    "        similarity_vector_t2 = []\n",
    "        word_vector_t2 = target_model.wv[word]\n",
    "        \n",
    "        for nn in neighbors_union:\n",
    "            neighbor_vector = target_model.wv[nn]\n",
    "            similarity_vector_t2.append(cosine_similarity(X=word_vector_t2.reshape(1,-1), Y=neighbor_vector.reshape(1,-1))[0][0])\n",
    "\n",
    "      # final cosine between cosines/ similarity vectors for t1 and t2\n",
    "        result1 = cosine_similarity(np.array([similarity_vector_t1]),\n",
    "                                   np.array([similarity_vector_t2])\n",
    "                                  )[0][0]\n",
    "  \n",
    "        shifts_PERanios5_list.append([i, periodo, word, result1, len(common_words), neighbors_t1, neighbors_t2, \n",
    "                                      len(neighbors_union)])\n",
    "  \n",
    "        \n",
    "     \n",
    "    return shifts_PERanios5_list\n",
    "\n",
    "# Funci√≥n para alinear m√∫ltiples per√≠odos secuencialmente\n",
    "def align_multiple_periods(models,shifts_PERanios5_list, i):\n",
    "    \n",
    "    for j in range(1, len(models)):\n",
    "        periodo = anios5_pairs[j - 1]\n",
    "        shifts_PERanios5_list = align_embeddings(models[j - 1], models[j], shifts_PERanios5_list, i, periodo)\n",
    "       \n",
    "    return shifts_PERanios5_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c00defe-8d02-4ae7-8827-f33accf07379",
   "metadata": {},
   "outputs": [],
   "source": [
    "shifts_PERanios5_list = []\n",
    "for i in range(iterations):\n",
    "    \n",
    "    np.random.seed(i)\n",
    "    rn.seed(i)\n",
    "    my_seed=i\n",
    "        \n",
    "    print('********************************************************')\n",
    "    print('Repeat No ', str(i))\n",
    "    \n",
    "    print(datetime.datetime.now())\n",
    "    \n",
    "    print('Training models for each anios5...')\n",
    "\n",
    "    for anios5, texts in tqdm(zip(PER5anios_df['Periodo_5anios'], PER5anios_df['T√≠tulo normalizado'])):\n",
    "        print(anios5)\n",
    "        model = Word2Vec(sentences=texts, vector_size=vector_size, window=5, min_count=20, workers=1, seed=my_seed)\n",
    "        model.save(models_dir+str(anios5)+'_'+str(i)+ \".mdl\")\n",
    "\n",
    "    print(datetime.datetime.now())\n",
    "\n",
    "    modelos = []\n",
    "    for anios in anios5_list:\n",
    "        m1 = Word2Vec.load(models_dir+str(anios)+'_'+str(i)+ \".mdl\")\n",
    "        modelos.append(m1)\n",
    "    \n",
    "    # Alinear embeddings secuencialmente\n",
    "    shifts_PERanios5_list = align_multiple_periods(modelos,shifts_PERanios5_list,i) \n",
    "\n",
    "\n",
    "    \n",
    "shifts_PER5anios_df = pd.DataFrame(\n",
    "    data=shifts_PERanios5_list, columns=['iteracion', 'anios5', 'palabra', 'similitud_semantica', 'vocabulario_comun', 'top25vecinos_1er_anios5', 'top25vecinos_2do_anios5', 'union_de_vecinos'])\n",
    "\n",
    "\n",
    "shifts_PER5anios_df.describe()\n",
    "\n",
    "shifts_PER5anios_df = shifts_PER5anios_df.sort_values('similitud_semantica', ascending=False).reset_index(drop=True)\n",
    "print(shifts_PER5anios_df.head(5))\n",
    "print('------------')\n",
    "print(shifts_PER5anios_df.tail(5))\n",
    "\n",
    "shifts_PER5anios_df.to_csv('./archivos_salidas/corrida_hamilton_estable'+str(run)+'_iteracion'+str(\n",
    "    iterations)+'_tamanio'+str(vector_size)+'_filas'+str(no_rows)+'.csv', index=False)\n",
    "\n",
    "topn_dict = {}\n",
    "X = []\n",
    "Y = []\n",
    "\n",
    "k=[5,10,20,30,50,100,200,300,500,600,700,800,1000] #\n",
    "\n",
    "for n in k:\n",
    "    \n",
    "    for iteration in range(iterations):\n",
    "        subdf = shifts_PER5anios_df.loc[(shifts_PER5anios_df['iteracion']==iteration)]\n",
    "        subdf = subdf.sort_values('similitud_semantica', ascending=False).reset_index(drop=True)\n",
    "        topn_dict[iteration] = subdf.head(n)['palabra'].to_list()\n",
    "    \n",
    "    topn_list_of_lists = [val for key, val in topn_dict.items()]\n",
    "\n",
    "    intersection = len(set(topn_list_of_lists[0]).intersection(*topn_list_of_lists))\n",
    "\n",
    "    Y.append(intersection/n)\n",
    "    X.append(n)\n",
    "    \n",
    "# print(X,Y)\n",
    "\n",
    "fig = plt.figure(figsize=(15, 8))\n",
    "\n",
    "fig.set_size_inches(20, 10)\n",
    "plt.scatter(X,Y)\n",
    "plt.plot(X,Y)\n",
    "plt.gca().tick_params(axis='both', which='major', labelsize=15)\n",
    "plt.ylim(0,1.)\n",
    "plt.xlabel('k', fontsize=18)\n",
    "plt.ylabel('Intersection@k', fontsize=18)\n",
    "plt.title('Estabilidad por Hamilton', fontsize=20)\n",
    "\n",
    "plt.savefig('./archivos_salidas/corrida_hamilton_estable'+str(run)+'_iteracion'+str(\n",
    "    iterations)+'_tamanio'+str(vector_size)+'_filas'+str(no_rows)+'.png', dpi=200,  bbox_inches='tight')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv_IL",
   "language": "python",
   "name": "myenv_il"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
