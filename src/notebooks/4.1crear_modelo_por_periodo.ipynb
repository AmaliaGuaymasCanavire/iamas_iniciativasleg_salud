{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a5ec4dc1-39a2-4728-b9a5-81e3419ba3f5",
   "metadata": {},
   "source": [
    "# 4.1  Crear modelos para cada período"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2071eb2f-4cc9-427a-b509-e9140df19534",
   "metadata": {},
   "source": [
    "\n",
    "Los títulos asociados a proyecto de LEY en promedio tiene 21 palabras, max 125 y mínimo 2 palabras.\n",
    "\n",
    "Periodo_5anios : cantidad de IL sobre ley y salud\n",
    "* 2019    1065\n",
    "* 2014    1008\n",
    "* 2009     775\n",
    "\n",
    "Analizando proyectos de IL de Salud:\n",
    "* [2009 - 2014) o [127 - 132)\n",
    "    * Número total de tokens: 7652\n",
    "    * Número de tokens únicos: 1713\n",
    "* [2014 - 2019) o [132 - 137)\n",
    "    * Número total de tokens: 9494\n",
    "    * Número de tokens únicos: 1967\n",
    "* [2019 - 2024) o [137 - 142)\n",
    "    * Número total de tokens: 9881\n",
    "    * Número de tokens únicos: 1875\n",
    "\n",
    "\n",
    "**Corpus IL:**\n",
    "* Las palabras aparecen pocas veces. Esto afectará el aprender del modelo. Embeddings inestables, esto afecta la detección de cambios semánticos.\n",
    "  \n",
    "* Esto afecta tareas posteriores\n",
    "    * Analizando las frecuencia de token por período:\n",
    "        * 2 veces es la mediana de veces en que aparece un token por periodo.\n",
    "        * 5 veces es el promedio de veces en que aparece un token por periodo.\n",
    "        * Cuartil 3 de Frecuencia = 8.5 \n",
    "        * 315 palabras con frecuencias extremas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9a7be913-4337-41de-884b-fb09b538db3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importar librerias\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "import sweetviz as sv\n",
    "import sys\n",
    "\n",
    "# Visualización\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "from matplotlib.lines import Line2D\n",
    "import matplotlib.colors as mcolors\n",
    "from matplotlib import colormaps\n",
    "\n",
    "from collections import Counter\n",
    "from itertools import islice\n",
    "\n",
    "from tqdm import tqdm\n",
    "tqdm.pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5f753f71-40b3-442b-9810-0449008f6ebb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configurar path\n",
    "### CONFIGURACION\n",
    "load_dotenv() # Cargar las variables de entorno del archivo .env\n",
    "BASE_DIR =  os.getenv(\"DIR_BASE\")\n",
    "RESULTADOS_DIR = os.getenv(\"DIR_DATOS_PROCESADOS\") # Acceder a las variables de entorno\n",
    "sys.path.append(BASE_DIR)\n",
    "sys.path.append(RESULTADOS_DIR)\n",
    "\n",
    "pd.set_option('display.max_colwidth', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f13b157c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# LEER OBJETO PARA DETECTAR CAMBIOS SEMANTICOS\n",
    "with open(RESULTADOS_DIR + 'periodo_5anios_df.pkl', 'rb') as file: \n",
    "    PER5anios_df = pickle.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a2fa0e6b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 3 entries, 0 to 2\n",
      "Data columns (total 3 columns):\n",
      " #   Column              Non-Null Count  Dtype \n",
      "---  ------              --------------  ----- \n",
      " 0   Periodo_5anios      3 non-null      int64 \n",
      " 1   Título normalizado  3 non-null      object\n",
      " 2   corpus              3 non-null      object\n",
      "dtypes: int64(1), object(2)\n",
      "memory usage: 204.0+ bytes\n"
     ]
    }
   ],
   "source": [
    "PER5anios_df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed0b833d-a579-4cf7-abb2-e1daad945ad0",
   "metadata": {},
   "source": [
    "### 2- Crear modelo Word2Vec \n",
    "Modelo inestable por corpus pequeño"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4199636-802b-4336-bbd5-e5995eb908bb",
   "metadata": {},
   "source": [
    "Entrenar embeddings Word2Vec para cada período.\n",
    "Usamos Word2Vec con \n",
    "\n",
    "```\n",
    "Word2Vec(\n",
    "    sentences=sentences,\n",
    "    vector_size=50,       # menor dimensión para evitar sobreajuste\n",
    "    window=10,            # más grande para capturar más contexto\n",
    "    min_count=2,          # más bajo para no perder vocabulario.\n",
    "    workers=4,\n",
    "    sg=1,                 # usar Skip-Gram, funciona mejor en corpus pequeños\n",
    "    epochs=50             # entrenar más veces para compensar pocos datos\n",
    ")\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0a3cf23c-e487-48f9-9878-e5930f7b4e3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import Word2Vec\n",
    "#https://radimrehurek.com/gensim/models/word2vec.html\n",
    "\n",
    "def entrenar_word2vec(sentencias, size=50, window=10, min_count=2,  w=4, s=1, e=50, seed=1):\n",
    "    return Word2Vec(sentencias, vector_size=size, window=window, min_count=min_count, workers=w, sg= s, epochs=e, seed=seed)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "808fb492-762c-4db6-b563-a7e636bbd0a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pares_primer_paso(lista_items):\n",
    "    return [(lista_items[i],lista_items[i+1]) for i in range(len(lista_items)-1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b4050fb6-6712-4d75-92c0-4b2b898408db",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(2009, 2014), (2014, 2019)]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "anios5_list = sorted(PER5anios_df['Periodo_5anios'].to_list())\n",
    "anios5_list\n",
    "anios5_pairs = pares_primer_paso(anios5_list)\n",
    "anios5_pairs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c3e05983-1ab0-4222-9d04-90ce9155a68a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['paro',\n",
       "  'cardiorrespiratorio',\n",
       "  'espectaculo',\n",
       "  'publico',\n",
       "  'futbol',\n",
       "  'regimen',\n",
       "  'presupuesto',\n",
       "  'minimo',\n",
       "  'necesario',\n",
       "  'materia',\n",
       "  'prevencion',\n",
       "  'atencion',\n",
       "  'primaria',\n",
       "  'basica'],\n",
       " ['ministerio',\n",
       "  'salud',\n",
       "  'nacion',\n",
       "  'registro',\n",
       "  'universal',\n",
       "  'sanitario',\n",
       "  'nacional'],\n",
       " ['incorporacion',\n",
       "  'calendario',\n",
       "  'nacional',\n",
       "  'vacunacion',\n",
       "  'dosis',\n",
       "  'vacuna',\n",
       "  'varicela',\n",
       "  'caracter',\n",
       "  'obligatorio']]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "PER5anios_df['corpus'][0][:3] # 2009"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2a1bd863-2e4c-4915-bff1-4633eba2f967",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2009\n",
      "775\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1it [00:01,  1.74s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2014\n",
      "1008\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2it [00:04,  2.25s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019\n",
      "1065\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "3it [00:06,  2.27s/it]\n"
     ]
    }
   ],
   "source": [
    "# Entrenar modelos de Word2Vec para cada período\n",
    "i = 1 # iteración\n",
    "modelos = [] # Cargamos modelos\n",
    "for anios5, corpus in tqdm(zip(PER5anios_df['Periodo_5anios'], PER5anios_df['corpus'])):\n",
    "    print(anios5)\n",
    "    print(len(corpus))\n",
    "    modelo = entrenar_word2vec(corpus, size=50, window=10, min_count=2, w=4, s=1, e=50, seed=1)\n",
    "    modelos.append(modelo)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f604923b-960a-437a-a8c2-e5662cdbb8e8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('poblacional', 0.6051187515258789),\n",
       " ('trabajo', 0.568244993686676),\n",
       " ('comit', 0.5647547841072083),\n",
       " ('ambiente', 0.5644502639770508),\n",
       " ('tumor', 0.5433409810066223),\n",
       " ('fortalecimiento', 0.5361788272857666),\n",
       " ('nacion', 0.5292761325836182),\n",
       " ('mistanasica', 0.5282478928565979),\n",
       " ('maligno', 0.5262343883514404),\n",
       " ('financiero', 0.52387535572052),\n",
       " ('poblacion', 0.5238097310066223),\n",
       " ('primaria', 0.5211458206176758),\n",
       " ('consultoria', 0.5189443230628967),\n",
       " ('nosocomial', 0.5157310366630554),\n",
       " ('intrahospitalaria', 0.5136682987213135)]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## para 2009 - 2013\n",
    "modelos[0].wv.most_similar(\"salud\", topn=15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e82d1c37-b7a6-4350-92f5-3baa6cf60135",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('ministerio', 0.6628741025924683),\n",
       " ('nacion', 0.6424374580383301),\n",
       " ('fortalecimiento', 0.582579493522644),\n",
       " ('tumor', 0.5776768326759338),\n",
       " ('ampliar', 0.5666766166687012),\n",
       " ('central', 0.5568865537643433),\n",
       " ('nosocomial', 0.5566364526748657),\n",
       " ('odontologia', 0.5511101484298706),\n",
       " ('figura', 0.5398802161216736),\n",
       " ('intrahospitalaria', 0.5384962558746338),\n",
       " ('implantabl', 0.5323957800865173),\n",
       " ('estatal', 0.5301596522331238),\n",
       " ('fiebre', 0.513197124004364),\n",
       " ('banco', 0.5130578279495239),\n",
       " ('vida', 0.5095268487930298)]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## para 2014 - 2018\n",
    "modelos[1].wv.most_similar(\"salud\", topn=15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e33182f9-a8a9-4ac9-b583-3360deb1822a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('figura', 0.5529130697250366),\n",
       " ('crear', 0.5481691956520081),\n",
       " ('fnpcp', 0.5183286070823669),\n",
       " ('hereditario', 0.5134453177452087),\n",
       " ('cientifica', 0.5126909613609314),\n",
       " ('bioquimica', 0.5119182467460632),\n",
       " ('modulo', 0.49890363216400146),\n",
       " ('publicacion', 0.4953594207763672),\n",
       " ('sis', 0.4892595112323761),\n",
       " ('procreacion', 0.48890772461891174),\n",
       " ('integrado', 0.4884296655654907),\n",
       " ('nacion', 0.48218780755996704),\n",
       " ('cesarea', 0.48045477271080017),\n",
       " ('ministerio', 0.4782728850841522),\n",
       " ('reproductivo', 0.47607582807540894)]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## para 2019 - 2023\n",
    "modelos[2].wv.most_similar(\"salud\", topn=15)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd3bee0f",
   "metadata": {},
   "source": [
    "### 3- Detectar cambio semántico por Orthogonal Procrustes :   (Hamilton et al., 2016)  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9dd4db47-f0aa-43e7-be6b-9f11fb3be4ea",
   "metadata": {},
   "source": [
    "Alinear embeddings con Procrustes: Alineamos los modelos secuencialmente para compararlos en el mismo espacio semántico.\n",
    "* Alinean embeddings de múltiples períodos secuencialmente con Iterative Procrustes.\n",
    "* Se usa el período inicial como referencia y cada nuevo período se alinea con la versión anterior.\n",
    "* Esto mantiene la estabilidad en el cambio semántico y reduce el ruido en palabras con alta variabilidad.\n",
    "\n",
    "**¿Por qué hay que alinear?**\n",
    "\n",
    "Cuando entrenás embeddings (por ejemplo, Word2Vec) en textos de distintos años, cada modelo puede:\n",
    "\n",
    "* Tener diferentes orientaciones en el espacio (rotaciones, reflexiones).\n",
    "\n",
    "* Usar coordenadas diferentes para significados similares.\n",
    "\n",
    "Aunque \"salud\" tenga el mismo significado en 2009 y en 2014, los vectores pueden estar en posiciones distintas.\n",
    "La alineación con Procrustes soluciona esto rotando y escalando los vectores para que estén en el mismo sistema de referencia.\n",
    "\n",
    "No cambiamos el significado de las palabras, sino que ajustamos el sistema de coordenadas para que los vectores sean comparables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "853ea551",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.nlp import estabilidad_procrustes as proc\n",
    "import numpy as np\n",
    "from scipy.linalg import orthogonal_procrustes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "57d2c9a3-9cd9-4d1d-8d5f-fb4337ab0e90",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Función para alinear embeddings con Procrustes scipy\n",
    "def alinear_procrustes(base_model, target_model):\n",
    "    \n",
    "    common_words = list(set(base_model.wv.index_to_key) & set(target_model.wv.index_to_key))\n",
    "    #print(common_words)\n",
    "    \n",
    "    base_matrix = np.array([base_model.wv[word] for word in common_words])\n",
    "    target_matrix = np.array([target_model.wv[word] for word in common_words])\n",
    "    \n",
    "    R, _ = orthogonal_procrustes(target_matrix, base_matrix)\n",
    "    \n",
    "    aligned_target = {word: target_model.wv[word] @ R for word in common_words}\n",
    "    return aligned_target\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "34f97db7",
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_comun = ['salud','accion']\n",
    "X = np.array([modelos[0].wv[word] for word in vocab_comun])\n",
    "Y = np.array([modelos[1].wv[word] for word in vocab_comun])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19cdbb82",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.76661927, -0.4325066 ,  0.25832516,  0.38662606, -0.05662229,\n",
       "       -0.64894587, -0.24123998,  0.02558997, -0.21201323, -0.47661552,\n",
       "       -0.40251607, -0.23828717,  0.4128283 ,  0.27515277, -0.34597382,\n",
       "        0.24998742,  0.29582503, -0.29708284, -0.15107588, -0.7316394 ,\n",
       "        0.0605019 , -0.40928772,  0.4454853 , -0.5765498 ,  0.55589855,\n",
       "       -0.10620517, -0.27302548,  0.06232678, -0.23466651,  0.68941194,\n",
       "        0.871782  , -0.1426986 ,  0.13816154, -0.1967091 , -0.05106308,\n",
       "       -0.41106868,  0.84974825,  0.3773513 ,  0.04463656, -0.3876453 ,\n",
       "        0.22333625,  0.21231668, -0.19567092,  0.18744278,  0.7696105 ,\n",
       "        0.33415315,  0.63159174,  0.557659  , -0.12445208, -0.20140213],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "160a96af",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.079476  , -0.55637676,  0.46066153,  0.5598775 ,  0.48113063,\n",
       "        0.3931902 ,  0.42459077,  1.630586  , -0.4863917 ,  0.3236691 ,\n",
       "       -0.5581608 ,  0.12543051, -0.1841846 , -0.2655787 , -0.00236468,\n",
       "        0.21027584,  0.93432343,  0.43968663, -0.23600185, -0.13143644,\n",
       "       -0.5664267 , -0.24251568,  0.63501155,  0.214907  , -0.1532986 ,\n",
       "        0.14523982, -0.27386513,  0.12166338,  0.08930604,  0.14271961,\n",
       "       -0.50580806,  0.28047282,  0.25264218, -0.30923456, -0.09082257,\n",
       "       -0.08189114,  0.35400146, -0.5037463 ,  0.63542306, -0.45921707,\n",
       "        0.24461576,  0.2660912 , -0.7460097 ,  0.25073925,  0.17295976,\n",
       "       -0.338223  ,  0.19380197, -0.65161324, -0.41050783, -0.24390787],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y[0] # el que voy a alinear"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9194a211",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calcular la rotación ortogonal\n",
    "R, _ = orthogonal_procrustes(Y, X)\n",
    "# Aplicar la rotación a todos los embeddings del segundo modelo\n",
    "modeloaligned = {word: modelos[1].wv[word] @ R for word in vocab_comun}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "79094282",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'salud': array([-0.83348626, -0.47276273,  0.28691936,  0.41803658, -0.06466002,\n",
       "        -0.71627843, -0.26220977,  0.03015995, -0.23308145, -0.5224773 ,\n",
       "        -0.43944013, -0.26498482,  0.45261234,  0.3049677 , -0.38380143,\n",
       "         0.27107888,  0.3247075 , -0.32217035, -0.16783506, -0.80108595,\n",
       "         0.06493317, -0.44274977,  0.49099347, -0.63768566,  0.60915005,\n",
       "        -0.11684465, -0.2984457 ,  0.06832987, -0.2624092 ,  0.75502205,\n",
       "         0.9536005 , -0.15109786,  0.14496748, -0.21565463, -0.0626744 ,\n",
       "        -0.44765797,  0.9315549 ,  0.41567862,  0.05258478, -0.42501223,\n",
       "         0.2477837 ,  0.22664644, -0.20954148,  0.19866678,  0.8449272 ,\n",
       "         0.36518753,  0.6902768 ,  0.61090595, -0.13362516, -0.21758482],\n",
       "       dtype=float32),\n",
       " 'accion': array([ 0.43567222, -0.06188819,  0.5899899 , -0.5007597 , -0.3444731 ,\n",
       "        -0.93525624,  0.14581755,  0.26963255, -0.19255148, -0.2505065 ,\n",
       "         0.00810702, -0.5833283 ,  0.22430229,  0.5504106 , -0.73323756,\n",
       "        -0.22872141,  0.2061815 ,  0.26910907, -0.34946772, -0.26858088,\n",
       "        -0.1372022 ,  0.50451845,  0.5552771 , -0.99073076,  0.26311162,\n",
       "        -0.10689257, -0.04003332,  0.0334722 , -0.7507657 ,  0.27397656,\n",
       "         0.20692034,  0.5730331 , -0.7160056 , -0.10551753, -0.8409088 ,\n",
       "         0.14434396,  0.4516217 ,  0.44349653,  0.46745652, -0.21182169,\n",
       "         0.47680748, -0.62984115,  0.49968475, -0.7294669 ,  0.55789304,\n",
       "         0.03961935,  0.07805559,  0.24293467,  0.275176  ,  0.28271875],\n",
       "       dtype=float32)}"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modeloaligned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1f0a632",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.5901762 , -0.32099983,  0.1798446 , -0.12335356, -0.08840335,\n",
       "       -0.2636055 , -0.15025623,  0.380592  , -0.23493706,  0.00736756,\n",
       "       -0.33755237, -0.23405166,  0.4462552 ,  0.20498578, -0.38673124,\n",
       "        0.20506981,  0.938567  , -0.45597395, -0.15547249, -1.2914217 ,\n",
       "        0.19843052, -0.48357117,  0.33145693, -0.23080048,  0.16478555,\n",
       "        0.25518608, -0.15124999, -0.05656921, -0.31502035,  0.9164427 ,\n",
       "        0.4544109 ,  0.01978845, -0.62647617,  0.38316867, -0.2646639 ,\n",
       "       -0.04165461,  1.0169672 ,  0.11497834,  0.25669977, -0.6127046 ,\n",
       "        0.14500146,  0.49579167, -0.51072884, -0.10588026,  0.8235962 ,\n",
       "       -0.00986712,  0.761114  ,  0.54713416, -0.06644504, -0.14222562],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Usando otro proyect ort\n",
    "modelo_alin = proc.smart_procrustes_align_gensim(modelos[0], modelos[1])\n",
    "modelo_alin.wv['salud']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5ba024d",
   "metadata": {},
   "source": [
    "### 4- Detectar cambio semántico por NN - Nearest Neighbors:  (Gonen et al., 2020)\n",
    "Introducen la intersección @k, es decir, la intersección de los k vecinos más cercanos de cada palabra en cada corpus, para medir la diferencia entre palabras vecinas. \n",
    "\n",
    "📌 Idea clave: En lugar de alinear embeddings, compara directamente los vecinos más cercanos en el espacio semántico.\n",
    "* Se calcula la intersección de los k vecinos más cercanos de una palabra en diferentes períodos.\n",
    "* Cuanto más cambien los vecinos, mayor será el cambio semántico."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "5ff17c65",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.nlp import estabilidad_NN as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcc44cd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def palabras_elegibles(m1, m2, palabras_top_m1, palabras_menosFrec_m1,\n",
    "                   palabras_top_m2, palabras_menosFrec_m2):\n",
    "    ''' \n",
    "    Recopila palabras aptas para el cálculo del desplazamiento semántico a partir de la intersección de los vocabularios que cumplen umbrales de frecuencia específicos\n",
    "    '''\n",
    "    \n",
    "    m1_vocab = [key for key, value in m1.wv.key_to_index.items() if key != ' ']\n",
    "    m2_vocab = [key for key, value in m2.wv.key_to_index.items() if key != ' ']\n",
    "\n",
    "    interseccion = set(m1_vocab).intersection(set(m2_vocab))\n",
    "    # Palabras muy frecuentes - top\n",
    "    top_frec = set(palabras_top_m1 + palabras_top_m2)\n",
    "    # Palabras menos frecuentes en base a umbral, ejemplo media\n",
    "    menos_frec = set(palabras_menosFrec_m1 + palabras_menosFrec_m2)\n",
    "\n",
    "    # Palabras limpias para buscar cambios de uso\n",
    "    final_list = [w for w in interseccion if\n",
    "                  w not in top_frec and w not in menos_frec and w != ' ']\n",
    "   \n",
    "    print(\"Cantidad Final lista de palabras: \",len(final_list))\n",
    "\n",
    "    return m1_vocab, m2_vocab, final_list\n",
    "\n",
    "def vecinos_elegibles(vocab1, vocab2, menos_frec_union):\n",
    "    ''' \n",
    "    Recopila palabras que son vecinos elegibles de las palabras estudiadas para el cambio semántico.\n",
    "    Las vecinos elegibles deben estar en ambos vocabularios modelo y \n",
    "    deben aparecer más de determinadas veces en cada corpus, para ello se tiene en cuenta los menos frecuentes.\n",
    "    '''\n",
    "\n",
    "    interseccion_vocabs = list(set(vocab1) & set(vocab2))\n",
    "    # se considera palabras repetidas en general\n",
    "    vecinos_plausibles = [w for w in interseccion_vocabs if\n",
    "                           w not in menos_frec_union and w != ' ']\n",
    "\n",
    "    return vecinos_plausibles\n",
    "\n",
    "def recolectar_vecinos_elegibles(palabra, m, vecinos_plausibles, topn_vecinos):\n",
    "    c = 0\n",
    "    out = []\n",
    "    for w, s in m.wv.most_similar(positive=[palabra], topn=topn_vecinos):\n",
    "        if w in vecinos_plausibles:\n",
    "            out.append(w)\n",
    "            c += 1\n",
    "        if c == topn_vecinos:\n",
    "            break\n",
    "\n",
    "    return (out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "f4165908",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Umbrales cables\n",
    "umbral_top = 5\n",
    "umbral_frec_menos = 5\n",
    "umbral_frec_menos_full  = 9 \n",
    "topn_vecinos = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "304d1eaa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2009\n",
      "count    1713.000000\n",
      "mean        4.467017\n",
      "std        10.621856\n",
      "min         1.000000\n",
      "25%         1.000000\n",
      "50%         2.000000\n",
      "75%         3.000000\n",
      "max       169.000000\n",
      "Name: Frecuencia, dtype: object\n",
      "2014\n",
      "count    1967.000000\n",
      "mean        4.826640\n",
      "std        12.238140\n",
      "min         1.000000\n",
      "25%         1.000000\n",
      "50%         2.000000\n",
      "75%         4.000000\n",
      "max       203.000000\n",
      "Name: Frecuencia, dtype: object\n",
      "2019\n",
      "count    1875.000000\n",
      "mean        5.269867\n",
      "std        13.972901\n",
      "min         1.000000\n",
      "25%         1.000000\n",
      "50%         2.000000\n",
      "75%         4.000000\n",
      "max       256.000000\n",
      "Name: Frecuencia, dtype: object\n"
     ]
    }
   ],
   "source": [
    "#Recopilar palabras para el análisis de cambio semántico que cumplan con los umbrales\n",
    "#Contar la frecuencia de palabras por década\n",
    "frec_anio_dic = {}\n",
    "top_palabras_dic = {}\n",
    "palabras_menosFrec_dic = {}\n",
    "palabras_menosFrecFull_dic = {}\n",
    "\n",
    "for anio in anios5_list:\n",
    "        df = pd.read_csv(RESULTADOS_DIR+'/archivos_out/frec_para_datos_limpios_por_desplaz_semantico_anios5_'+str(anio)+'.csv')\n",
    "        print(anio)\n",
    "\n",
    "        print(df.Frecuencia.describe().apply(lambda x: format(x, 'f')))\n",
    "        df = df.sort_values('Frecuencia', ascending=False)\n",
    "        frec_anio_dic[anio] = df\n",
    "\n",
    "        top_palabras_dic[anio] = df.Palabra.head(umbral_top).to_list()\n",
    "        palabras_menosFrec_dic[anio] = df.loc[df.Frecuencia < umbral_frec_menos].Palabra.to_list()\n",
    "        palabras_menosFrecFull_dic[anio] = df.loc[df.Frecuencia < umbral_frec_menos_full].Palabra.to_list()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63477b1c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cantidad Final lista de palabras:  246\n"
     ]
    }
   ],
   "source": [
    "m1 = modelos[0]\n",
    "m2 = modelos[1]\n",
    "m1_vocab, m2_vocab, final_list = palabras_elegibles(m1, m2, \n",
    "                top_palabras_dic[2009], palabras_menosFrec_dic[2009],\n",
    "                top_palabras_dic[2014], palabras_menosFrec_dic[2014]\n",
    "                )\n",
    "palabras_menos_union = set(palabras_menosFrecFull_dic[2009]+palabras_menosFrecFull_dic[2014])\n",
    "vecinos = vecinos_elegibles(m1_vocab, m2_vocab, palabras_menos_union)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "de720fe3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['nacion', 'ministerio', 'atencion', 'registro', 'cancer', 'cuidado', 'derecho', 'federal', 'ley', 'publicar', 'acceso', 'beneficiario']\n",
      "['ministerio', 'nacion', 'cuidado', 'materno', 'creacion', 'registro', 'fondo', 'nutricion', 'atencion', 'medico', 'persona']\n",
      "{'nacion', 'cuidado', 'ministerio', 'atencion', 'registro'}\n"
     ]
    }
   ],
   "source": [
    "palabra = \"salud\"\n",
    "neighbors_t1 = recolectar_vecinos_elegibles(palabra, m1, vecinos, topn_vecinos)\n",
    "neighbors_t2 = recolectar_vecinos_elegibles(palabra, m2, vecinos, topn_vecinos)\n",
    "neighbors = set(neighbors_t1).intersection(set(neighbors_t2)) \n",
    "score = -len(neighbors)\n",
    "print(neighbors_t1)\n",
    "print(neighbors_t2)\n",
    "print(neighbors)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv_IL",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
